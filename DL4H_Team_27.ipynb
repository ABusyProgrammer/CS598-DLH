{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NOTE**\n",
        "This submission is only built for the *DRAFT* stage; therefore, the final report and results are not ready yet."
      ],
      "metadata": {
        "id": "m88ay8BPlgKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Author\n",
        "**Aryan Kukreja**\n",
        "\n",
        "aryansk2@illinois.edu\n",
        "\n",
        "UIN: 652936393\n",
        "\n",
        "GitHub Repo: https://github.com/ABusyProgrammer/CS598-DLH"
      ],
      "metadata": {
        "id": "aRK6cqV9BT_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In the rapidly evolving field of healthcare analytics, Electronic Health Records (EHRs) have emerged as a vital resource. These records, which contain a wealth of patient information, hold the potential to significantly improve patient outcomes and optimize the allocation of healthcare resources. However, the inherent complexity of EHRs, characterized by high sparsity and irregular observations, presents a formidable challenge. Traditional time series analysis methods, designed for densely sampled data, often fall short when applied to EHRs. While state-of-the-art methods such as the various categories and implementations of neural network models and attention mechanisms have shown promising results, they come with their own set of limitations. These methods often necessitate substantial computational resources and involve truncating inputs, which can compromise the accuracy of the predictions.\n",
        "\n",
        "Addressing these challenges, this paper introduces a groundbreaking approach with the Dual Event Time Transformer (DuETT). DuETT represents a significant departure from traditional methods, offering an innovative architecture that attends to both the time and event type dimensions of EHR data. This unique capability allows DuETT to transform sparse time series into a regular sequence, thereby enabling the application of larger and deeper neural networks. This transformation process, which is at the heart of DuETT’s innovation, effectively handles the irregularity and sparsity of EHR data. The effectiveness of DuETT is not just theoretical; it has been empirically demonstrated. DuETT outperforms state-of-the-art deep learning models on multiple downstream tasks using the MIMIC-IV and PhysioNet-2012 EHR datasets. By providing a robust and effective representation of EHR data, DuETT makes a significant contribution to the field of healthcare analytics. Its state-of-the-art performance and potential for practical applications in hospitals underscore the importance and relevance of this research in the ongoing efforts to leverage EHRs for improved healthcare outcomes.\n",
        "\n",
        "Paper being analyzed: [DuETT: Dual Event Time Transformer for Electronic Health\n",
        "Records](https://arxiv.org/pdf/2304.13017.pdf)"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "The following are some of the key hypothesis that this paper looks to test:\n",
        "1. **Capture EHR Structure**: If DuETT attends over both time and event dimensions of EHR data, then it can produce robust representations that capture the structure of EHR data.\n",
        "2. **Handle Sparsity and Irregularity**: If DuETT transforms sparse and irregularly sampled time series into regular sequences with fixed length, then it can reduce computational complexity and handle the sparsity and irregularity of EHR data.\n",
        "3. **Improve Model Performance**: If DuETT is applied to multiple downstream tasks using the MIMIC-IV and PhysioNet-2012 EHR datasets, then it can outperform state-of-the-art deep learning models.\n",
        "4. **Leverage Self-Supervised Learning**: If DuETT utilizes self-supervised prediction tasks for model pre-training, then it can enable the training of larger models with limited labeled data.\n",
        "\n",
        "These hypotheses form the basis of the paper’s investigation into the effectiveness of the DuETT architecture for modeling EHR data. Each hypothesis is designed to test a specific aspect of DuETT’s capabilities and its potential advantages over existing methods."
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation\n",
        "\n",
        "The following is an attempt to replicate the paper I have selected."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "The following is where we will import all the libraries in general, to keep the code clean throughout the rest of the file."
      ],
      "metadata": {
        "id": "rfuFT-n4df1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip numpy==1.21.5\n",
        "!pip install pytorch-lightning==1.6.1\n",
        "!pip install torch==1.13.1\n",
        "!pip install torchaudio==0.13.1\n",
        "!pip install torchvision==0.14.1\n",
        "!pip install x-transformers==1.5.3\n",
        "!pip install torchtime==0.5.1\n",
        "!pip install torchmetrics==0.8.0"
      ],
      "metadata": {
        "id": "h2XZc-Z-32nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import  packages you need\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtime.data import PhysioNet2012\n",
        "from multiprocessing import Manager\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import torchmetrics\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import x_transformers\n",
        "\n",
        "import torch.multiprocessing\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "import pytorch_lightning as pl\n",
        "import argparse"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing Utilities\n",
        "\n",
        "Prior to conducting the actual training itself, the data processing pipeline for a machine learning model requires the use of a data pre-processing to ensure that the data that will be used for training is clean and refined to produce valid results. This paper performs all these steps as part of the [physionet.py](https://github.com/layer6ai-labs/DuETT/blob/master/physionet.py) file, which had the `PhysioNetDataModule` and `PhysioNetDataset` classes defined. Each of them would do the following:\n",
        "1. `PhysioNetDataset`:\n",
        "   1. **Initialization**: Sets up the dataset split (train, validation, test), number of timesteps, and whether to use a temporary cache.\n",
        "   1. **Setup**: Prepares the data by loading it from the PhysioNet2012 source and calculating statistics like mean, standard deviation, max, and min for normalization.\n",
        "   1. **Data Retrieval**: Implements methods to get the length of the dataset and retrieve individual items, which includes preprocessing and normalizing the time-series and static data.\n",
        "2. `PhysioNetDataModule`:\n",
        "   1. **Initialization**: Configures the batch size, number of workers, and other DataLoader parameters.\n",
        "   1. **Setup**: Calls the setup method of the PhysioNetDataset instances for different splits.\n",
        "   1. **Data Loaders**: Provides DataLoader instances for training, validation, and testing phases, which use the collate_into_seqs function to batch the data.\n",
        "\n",
        "As part of my attempts to replicate this paper, I have attempted to simplify the overall structure of the data pre-processing code into a single class for easier understanding, and have made some optimizations with reference to the rest of the code as well."
      ],
      "metadata": {
        "id": "JSNOvVILdz5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PhysioNetDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, split_name, n_timesteps=32, use_temp_cache=False, batch_size=8, num_workers=1, prefetch_factor=2, **kwargs):\n",
        "        super().__init__()\n",
        "        self.split_name = split_name\n",
        "        self.n_timesteps = n_timesteps\n",
        "        self.temp_cache = Manager().dict() if use_temp_cache else None\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.prefetch_factor = prefetch_factor\n",
        "        self.setup()\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Initialize the dataset with the specified split\n",
        "        tt_data = PhysioNet2012(self.split_name, train_prop=0.7, val_prop=0.15, time=False, seed=0)\n",
        "        self.X = tt_data.X\n",
        "        self.y = tt_data.y\n",
        "        self.calculate_statistics()\n",
        "\n",
        "    def calculate_statistics(self):\n",
        "        # Calculate statistics for normalization\n",
        "        self.means = []\n",
        "        self.stds = []\n",
        "        self.maxes = []\n",
        "        self.mins = []\n",
        "        for i in range(self.X.shape[2]):\n",
        "            vals = self.X[:,:,i].flatten()\n",
        "            vals = vals[~torch.isnan(vals)]\n",
        "            self.means.append(vals.mean())\n",
        "            self.stds.append(vals.std())\n",
        "            self.maxes.append(vals.max())\n",
        "            self.mins.append(vals.min())\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of samples in the dataset\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # Retrieve a sample and its label, applying normalization\n",
        "        if self.temp_cache is not None and i in self.temp_cache:\n",
        "            return self.temp_cache[i]\n",
        "        ins = self.X[i, ~torch.isnan(self.X[i,:,0]), :]\n",
        "        x, y = self.process_sample(ins)\n",
        "        if self.temp_cache is not None:\n",
        "            self.temp_cache[i] = (x, y)\n",
        "        return x, y\n",
        "\n",
        "    def process_sample(self, ins):\n",
        "        # Process a single sample from the dataset\n",
        "        time = ins[:,0] / 60 / 24\n",
        "        x_static, x_ts, bin_ends = self.create_tensors(time)\n",
        "        self.populate_tensors(ins, time, x_static, x_ts, bin_ends)\n",
        "        y = self.y[i,0]\n",
        "        return (x_ts, x_static, bin_ends), y\n",
        "\n",
        "    def create_tensors(self, time):\n",
        "        # Create tensors for time-series and static features\n",
        "        x_static = torch.zeros(self.d_static_num())\n",
        "        x_ts = torch.zeros((self.n_timesteps, self.d_time_series_num()*2))\n",
        "        bin_ends = torch.arange(1, self.n_timesteps+1) / self.n_timesteps * time[-1]\n",
        "        return x_static, x_ts, bin_ends\n",
        "\n",
        "    def populate_tensors(self, ins, time, x_static, x_ts, bin_ends):\n",
        "        # Populate the tensors with normalized data\n",
        "        for i_t, t in enumerate(time):\n",
        "            bin = self.n_timesteps - 1 if t == time[-1] else int(t / time[-1] * self.n_timesteps)\n",
        "            for i_ts in range(1,37):\n",
        "                x_i = ins[i_t,i_ts]\n",
        "                if not torch.isnan(x_i).item():\n",
        "                    x_ts[bin, i_ts-1] = (x_i - self.means[i_ts])/(self.stds[i_ts] + 1e-7)\n",
        "                    x_ts[bin, i_ts-1+self.d_time_series_num()] += 1\n",
        "        for i_tab in range(37,45):\n",
        "            x_i = ins[0, i_tab]\n",
        "            x_i = (x_i - self.means[i_tab])/(self.stds[i_tab] + 1e-7)\n",
        "            x_static[i_tab-37] = x_i.nan_to_num(0.)\n",
        "\n",
        "    def d_static_num(self):\n",
        "        # Return the number of static features\n",
        "        return 8\n",
        "\n",
        "    def d_time_series_num(self):\n",
        "        # Return the number of time-series features\n",
        "        return 36\n",
        "\n",
        "    def d_target(self):\n",
        "        # Return the dimension of the target variable\n",
        "        return 1\n",
        "\n",
        "    def pos_frac(self):\n",
        "        # Return the fraction of positive samples\n",
        "        return self.y.mean().numpy()\n",
        "\n",
        "    def collate_into_seqs(self, batch):\n",
        "        # Collate a batch of samples into sequences\n",
        "        xs, ys = zip(*batch)\n",
        "        return zip(*xs), ys\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Return a DataLoader for the training set\n",
        "        return DataLoader(self, shuffle=True, batch_size=self.batch_size, prefetch_factor=self.prefetch_factor, collate_fn=self.collate_into_seqs, num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # Return a DataLoader for the validation set\n",
        "        return DataLoader(self, batch_size=self.batch_size, prefetch_factor=self.prefetch_factor, collate_fn=self.collate_into_seqs, num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # Return a DataLoader for the test set\n",
        "        return DataLoader(self, batch_size=self.batch_size, prefetch_factor=self.prefetch_factor, collate_fn=self.collate_into_seqs, num_workers=self.num_workers)\n"
      ],
      "metadata": {
        "id": "AR2MQAw3p29d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "Below is the (***in-progress***) implementation of the model for the training."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Normalization\n",
        "Batch normalization is a technique used to increase the stability of a neural network. It normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation. Here, it s designed to apply this normalization along the last dimension of the input tensor. This can be particularly useful when dealing with multi-dimensional inputs where you want to apply normalization not over the entire batch, but separately for each feature in the last dimension."
      ],
      "metadata": {
        "id": "FBvrku-mw-Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Batch Normalization for the last dimension of a tensor\n",
        "class BatchNormLastDim(nn.Module):\n",
        "    def __init__(self, d, **kwargs):\n",
        "        super().__init__()\n",
        "        self.batch_norm = nn.BatchNorm1d(d, **kwargs)\n",
        "\n",
        "    # Apply batch normalization to the last dimension\n",
        "    def forward(self, x):\n",
        "        if x.ndim == 2:\n",
        "            return self.batch_norm(x)\n",
        "        elif x.ndim == 3:\n",
        "            return self.batch_norm(x.transpose(1, 2)).transpose(1, 2)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Not implemented in the paper... Anything I can do here?\")"
      ],
      "metadata": {
        "id": "YeYrDNMKwTOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron Component\n",
        "This paper relies on a simple implementation of a simple multi-layer perceptron that is used when building the overall neural network architecture. Due to its simple implementation, its been kept largely the same as in the original paper. (Might change this later)."
      ],
      "metadata": {
        "id": "LQOCv4lPxRyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple MLP (Multi-Layer Perceptron) with customizable layers and options\n",
        "def simple_mlp(d_in, d_out, n_hidden, d_hidden, final_activation=False, input_batch_norm=False, hidden_batch_norm=False, dropout=0., activation=nn.ReLU):\n",
        "    layers = []\n",
        "    # Input batch normalization layer\n",
        "    if input_batch_norm:\n",
        "        layers.append(BatchNormLastDim(d_in))\n",
        "    # Input linear layer\n",
        "    layers.append(nn.Linear(d_in, d_hidden if n_hidden > 0 else d_out))\n",
        "    # Hidden layers\n",
        "    for _ in range(n_hidden):\n",
        "        layers.extend([\n",
        "            activation(),\n",
        "            nn.Dropout(dropout),\n",
        "            BatchNormLastDim(d_hidden) if hidden_batch_norm else nn.Identity(),\n",
        "            nn.Linear(d_hidden, d_hidden)\n",
        "        ])\n",
        "    # Final linear layer\n",
        "    layers.append(nn.Linear(d_hidden if n_hidden > 0 else d_in, d_out))\n",
        "    # Final activation layer\n",
        "    if final_activation:\n",
        "        layers.append(activation())\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "IzD7OAfqwe9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Pre-Training and Fine-Tuning\n",
        "These are helper methods. The `pretrain_model` method is used to initialize a model with a given set of parameters for pre-training. The `fine_tune_model` method, on the other hand, is called within a loop (later in this code) to iteratively fine-tune the model."
      ],
      "metadata": {
        "id": "R6iLvCEp08Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model pretraining function\n",
        "def pretrain_model(d_static_num, d_time_series_num, d_target, **kwargs):\n",
        "    return Model(d_static_num, d_time_series_num, d_target, **kwargs)\n",
        "\n",
        "# Model fine-tuning function\n",
        "def fine_tune_model(ckpt_path, **kwargs):\n",
        "    return Model.load_from_checkpoint(ckpt_path, pretrain=False, aug_noise=0., aug_mask=0.5, transformer_dropout=0.5, lr=1.e-4, weight_decay=1.e-5, fusion_method='rep_token', **kwargs)"
      ],
      "metadata": {
        "id": "zr2gx2v9wj9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core Model\n",
        "This is the main model class that defines the key training functions/methods such as `forward()`. It is a PyTorch Lightning module designed for training and evaluating a machine learning model for time-series data analysis that is being conducted here to eveluate the DuETT approach."
      ],
      "metadata": {
        "id": "aVchmeTO2Yrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(pl.LightningModule):\n",
        "    # Model initialization\n",
        "    def __init__(self, d_static_num, d_time_series_num, d_target, lr=3.e-4, weight_decay=1.e-1, glu=False, scalenorm=True, n_hidden_mlp_embedding=1, d_hidden_mlp_embedding=64, d_embedding=24, d_feedforward=512, max_len=48, n_transformer_head=2, n_duett_layers=2, d_hidden_tab_encoder=128, n_hidden_tab_encoder=1, norm_first=True, fusion_method='masked_embed', n_hidden_head=1, d_hidden_head=64, aug_noise=0., aug_mask=0., pretrain=True, pretrain_masked_steps=1, pretrain_n_hidden=0, pretrain_d_hidden=64, pretrain_dropout=0.5, pretrain_value=True, pretrain_presence=True, pretrain_presence_weight=0.2, predict_events=True, transformer_dropout=0., pos_frac=None, freeze_encoder=False, seed=0, save_representation=None, masked_transform_timesteps=32, **kwargs):\n",
        "        super().__init__()\n",
        "        # Model configuration parameters\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.d_time_series_num = d_time_series_num\n",
        "        self.d_target = d_target\n",
        "        self.d_embedding = d_embedding\n",
        "        self.max_len = max_len\n",
        "        self.pretrain = pretrain\n",
        "        self.pretrain_masked_steps = pretrain_masked_steps\n",
        "        self.pretrain_dropout = pretrain_dropout\n",
        "        self.freeze_encoder = freeze_encoder\n",
        "        self.set_pos_frac(pos_frac)\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.aug_noise = aug_noise\n",
        "        self.aug_mask = aug_mask\n",
        "        self.fusion_method = fusion_method\n",
        "        self.pretrain_presence = pretrain_presence\n",
        "        self.pretrain_presence_weight = pretrain_presence_weight\n",
        "        self.predict_events = predict_events\n",
        "        self.masked_transform_timesteps = masked_transform_timesteps\n",
        "        self.pretrain_value = pretrain_value\n",
        "        self.save_representation = save_representation\n",
        "        # Special embeddings for different purposes\n",
        "        self.special_embeddings = nn.Embedding(8, d_embedding)\n",
        "        # Embedding layers for time series features\n",
        "        self.embedding_layers = nn.ModuleList([\n",
        "            simple_mlp(2, d_embedding, n_hidden_mlp_embedding, d_hidden_mlp_embedding, hidden_batch_norm=True)\n",
        "            for _ in range(d_time_series_num)\n",
        "        ])\n",
        "        # Embedding for the number of observations\n",
        "        self.n_obs_embedding = nn.Embedding(16, 1)\n",
        "        # Feedforward dimensions\n",
        "        if d_feedforward is None:\n",
        "            d_feedforward = d_embedding * 4\n",
        "        et_dim = d_embedding * (masked_transform_timesteps + 1)\n",
        "        tt_dim = d_embedding * (d_time_series_num + 1)\n",
        "        # Transformer layers for event and time features\n",
        "        self.event_transformers = nn.ModuleList([\n",
        "            x_transformers.Encoder(dim=et_dim, depth=1, heads=n_transformer_head, pre_norm=norm_first, use_scalenorm=scalenorm, attn_dim_head=d_embedding // n_transformer_head, ff_glu=glu, ff_mult=d_feedforward / et_dim, attn_dropout=transformer_dropout, ff_dropout=transformer_dropout)\n",
        "            for _ in range(n_duett_layers)\n",
        "        ])\n",
        "        self.full_event_embedding = nn.Embedding(d_time_series_num + 1, et_dim)\n",
        "        self.time_transformers = nn.ModuleList([\n",
        "            x_transformers.Encoder(dim=tt_dim, depth=1, heads=n_transformer_head, pre_norm=norm_first, use_scalenorm=scalenorm, attn_dim_head=d_embedding // n_transformer_head, ff_glu=glu, ff_mult=d_feedforward / tt_dim, attn_dropout=transformer_dropout, ff_dropout=transformer_dropout)\n",
        "            for _ in range(n_duett_layers)\n",
        "        ])\n",
        "        self.full_time_embedding = self.cve(batch_norm=True, d_embedding=tt_dim)\n",
        "        self.full_rep_embedding = nn.Embedding(tt_dim, 1)\n",
        "        # Representation dimension\n",
        "        d_representation = d_embedding * (d_time_series_num + 1)  # time_series + static\n",
        "        # Prediction head\n",
        "        self.head = simple_mlp(d_representation, d_target, n_hidden_head, d_hidden_head, hidden_batch_norm=True, final_activation=False, activation=nn.ReLU)\n",
        "        # Pretraining projection layers\n",
        "        self.pretrain_value_proj = simple_mlp(d_representation, d_time_series_num, pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
        "        if self.pretrain_presence:\n",
        "            self.pretrain_presence_proj = simple_mlp(d_representation, d_time_series_num, pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
        "        if self.predict_events:\n",
        "            self.predict_events_proj = simple_mlp(et_dim, masked_transform_timesteps, pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
        "            if self.pretrain_presence:\n",
        "                self.predict_events_presence_proj = simple_mlp(et_dim, masked_transform_timesteps, pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
        "        # Encoder for static features\n",
        "        self.tab_encoder = simple_mlp(d_static_num, d_embedding, n_hidden_tab_encoder, d_hidden_tab_encoder, hidden_batch_norm=True)\n",
        "        # Loss functions\n",
        "        self.pretrain_loss = F.mse_loss\n",
        "        self.loss_function = F.binary_cross_entropy_with_logits\n",
        "        self.pretrain_presence_loss = F.binary_cross_entropy_with_logits\n",
        "        # Metrics\n",
        "        num_classes = None if d_target == 1 else d_target\n",
        "        self.train_auroc = torchmetrics.AUROC(num_classes=num_classes)\n",
        "        self.val_auroc = torchmetrics.AUROC(num_classes=num_classes)\n",
        "        self.train_ap = torchmetrics.AveragePrecision(num_classes=num_classes)\n",
        "        self.val_ap = torchmetrics.AveragePrecision(num_classes=num_classes)\n",
        "        self.test_auroc = torchmetrics.AUROC(num_classes=num_classes)\n",
        "        self.test_ap = torchmetrics.AveragePrecision(num_classes=num_classes)\n",
        "\n",
        "    # Set the positive fraction for weighted loss calculation\n",
        "    def set_pos_frac(self, pos_frac):\n",
        "        if type(pos_frac) == list:\n",
        "            pos_frac = torch.tensor(pos_frac, device=torch.device('cuda'))\n",
        "        self.pos_frac = pos_frac\n",
        "        if pos_frac is not None:\n",
        "            self.pos_weight = 1 / (2 * pos_frac)\n",
        "            self.neg_weight = 1 / (2 * (1 - pos_frac))\n",
        "\n",
        "    # Custom value embedding function\n",
        "    def cve(self, d_embedding=None, batch_norm=False):\n",
        "        if d_embedding is None:\n",
        "            d_embedding = self.d_embedding\n",
        "        d_hidden = int(np.sqrt(d_embedding))\n",
        "        layers = [nn.Linear(1, d_hidden), nn.Tanh()]\n",
        "        if batch_norm:\n",
        "            layers.append(BatchNormLastDim(d_hidden))\n",
        "        layers.append(nn.Linear(d_hidden, d_embedding))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    # Convert features to model input\n",
        "    def feats_to_input(self, x, batch_size, limits=None):\n",
        "        # Unpack the input tuple\n",
        "        xs_ts, xs_static, times = x\n",
        "        xs_ts = list(xs_ts)\n",
        "\n",
        "        # Process each time series feature\n",
        "        for i, f in enumerate(xs_ts):\n",
        "            n_vars = f.shape[1] // 2  # Number of variables in the feature\n",
        "\n",
        "            # Truncate the feature to the maximum length if necessary\n",
        "            if f.shape[0] > self.max_len:\n",
        "                f = f[-self.max_len:]\n",
        "                times[i] = times[i][-self.max_len:]\n",
        "\n",
        "            # Apply noise augmentation during training\n",
        "            if self.training and self.aug_noise > 0 and not self.pretrain:\n",
        "                f[:, :n_vars] += self.aug_noise * torch.randn_like(f[:, :n_vars]) * f[:, n_vars:]\n",
        "\n",
        "            # Add a new dimension for the mask\n",
        "            f = torch.cat((f, torch.zeros_like(f[:, :1])), dim=1)\n",
        "\n",
        "            # Apply mask augmentation during training\n",
        "            if self.training and self.aug_mask > 0 and not self.pretrain:\n",
        "                mask = torch.rand(f.shape[0]) < self.aug_mask\n",
        "                f[mask, :] = 0.\n",
        "                f[mask, -1] = 1.\n",
        "\n",
        "            xs_ts[i] = f\n",
        "\n",
        "        # Determine the maximum number of timesteps across all features\n",
        "        n_timesteps = [len(ts) for ts in times]\n",
        "        pad_to = max(n_timesteps)\n",
        "\n",
        "        # Pad the time series and static features to have the same length\n",
        "        xs_ts = torch.stack([F.pad(t, (0, 0, 0, pad_to - t.shape[0])) for t in xs_ts]).to(self.device)\n",
        "        xs_times = torch.stack([F.pad(t, (0, pad_to - t.shape[0])) for t in times]).to(self.device)\n",
        "        xs_static = torch.stack(xs_static).to(self.device)\n",
        "\n",
        "        # Apply noise augmentation to static features during training\n",
        "        if self.training and self.aug_noise > 0 and not self.pretrain:\n",
        "            xs_static += self.aug_noise * torch.randn_like(xs_static)\n",
        "\n",
        "        return xs_static, xs_ts, xs_times, n_timesteps\n",
        "\n",
        "    def pretrain_prep_batch(self, x, batch_size):\n",
        "        # Prepare the batch for pretraining by augmenting and masking the data\n",
        "        xs_static, xs_ts, xs_times, n_timesteps = self.feats_to_input(x, batch_size)\n",
        "        n_steps = xs_ts.shape[1]\n",
        "        n_vars = (xs_ts.shape[2] - 1) // 2\n",
        "\n",
        "        # Initialize lists to hold targets for pretraining tasks\n",
        "        y_ts = []\n",
        "        y_ts_n_obs = []\n",
        "        y_events = []\n",
        "        y_events_mask = []\n",
        "\n",
        "        # Clone the time series features to apply masking\n",
        "        xs_ts_clipped = xs_ts.clone()\n",
        "\n",
        "        # Iterate over each sample in the batch\n",
        "        for batch_i, n in enumerate(n_timesteps):\n",
        "            # Determine indices to mask based on the number of timesteps and pretraining configuration\n",
        "            mask_i = self.rng.choice(np.arange(n), size=min(self.pretrain_masked_steps, n), replace=False)\n",
        "\n",
        "            # Store the original values and observation flags for the masked timesteps\n",
        "            y_ts.append(xs_ts[batch_i, mask_i, :n_vars])\n",
        "            y_ts_n_obs.append(xs_ts[batch_i, mask_i, n_vars:2*n_vars])\n",
        "\n",
        "            # Apply masking to the cloned features\n",
        "            xs_ts_clipped[batch_i, mask_i, :] = 0.\n",
        "            xs_ts_clipped[batch_i, mask_i, -1] = 1.\n",
        "\n",
        "            # If event prediction is enabled, prepare event targets and masks\n",
        "            if self.predict_events:\n",
        "                event_mask_i = self.rng.choice(np.arange(0, self.d_time_series_num))\n",
        "                y_events.append(xs_ts[batch_i, :, event_mask_i])\n",
        "                y_events_mask.append(xs_ts[batch_i, :, event_mask_i + n_vars].clip(0, 1))\n",
        "                xs_ts_clipped[batch_i, :, event_mask_i] = 0\n",
        "                xs_ts_clipped[batch_i, :, event_mask_i + n_vars] = -1\n",
        "\n",
        "        # Convert lists to tensors\n",
        "        y_ts = torch.stack(y_ts)\n",
        "        y_ts_n_obs = torch.stack(y_ts_n_obs)\n",
        "        y_ts_masks = y_ts_n_obs.clip(0, 1)\n",
        "\n",
        "        # Handle event targets and masks if applicable\n",
        "        if len(y_events) > 0:\n",
        "            y_events = torch.stack(y_events)\n",
        "            y_events_mask = torch.stack(y_events_mask)\n",
        "\n",
        "        # Apply dropout to the masked features if configured\n",
        "        if self.pretrain_dropout > 0:\n",
        "            keep = self.rng.random((batch_size, n_vars)) > self.pretrain_dropout\n",
        "            keep = torch.tensor(keep, device=xs_ts.device)\n",
        "            keep = torch.cat((keep.tile(1, 2), torch.ones((batch_size, 1), device=keep.device)), dim=1)\n",
        "            xs_ts_clipped *= torch.logical_or(keep.unsqueeze(1), xs_ts_clipped == -1)\n",
        "\n",
        "        # Return the prepared batch along with the targets and masks\n",
        "        return (xs_static, xs_ts_clipped, xs_times, n_timesteps), y_ts, y_ts_masks, y_events, y_events_mask\n",
        "\n",
        "    def forward(self, x, pretrain=False, representation=False):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (tuple): Input data consisting of features and times.\n",
        "            pretrain (bool): Flag to indicate if the model is in pretraining mode.\n",
        "            representation (bool): Flag to indicate if the model should return representations.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output of the model which could be predictions, representations, or pretraining projections.\n",
        "        \"\"\"\n",
        "        # Unpack input data\n",
        "        xs_static, xs_feats, xs_times, n_timesteps = x\n",
        "        n_vars = xs_feats.shape[2] // 2  # Number of variables based on feature shape\n",
        "\n",
        "        # Prepare masks and embeddings for event prediction if enabled\n",
        "        if self.predict_events:\n",
        "            event_mask_inds = xs_feats[:, :, n_vars:n_vars*2] == -1\n",
        "            event_mask_inds = torch.cat((event_mask_inds, torch.zeros(xs_feats.shape[:2] + (1,), device=xs_feats.device, dtype=torch.bool)), dim=2)\n",
        "            event_mask_inds = torch.cat((event_mask_inds, event_mask_inds[:, :1, :]), dim=1)\n",
        "            n_obs_inds = xs_feats[:, :, n_vars:n_vars*2].to(int).clip(0, self.n_obs_embedding.num_embeddings - 1)\n",
        "            xs_feats[:, :, n_vars:n_vars*2] = self.n_obs_embedding(n_obs_inds).squeeze(-1)\n",
        "\n",
        "        # Process features for embedding\n",
        "        embedding_layer_input = torch.empty(xs_feats.shape[:-1] + (n_vars, 2), dtype=xs_feats.dtype, device=xs_feats.device)\n",
        "        embedding_layer_input[:, :, :, 0] = xs_feats[:, :, :n_vars]\n",
        "        embedding_layer_input[:, :, :, 1] = xs_feats[:, :, n_vars:n_vars*2]\n",
        "\n",
        "        # Embedding and transformation operations\n",
        "        psi = torch.zeros((xs_feats.shape[0], xs_feats.shape[1]+1, n_vars+1, self.d_embedding), dtype=xs_feats.dtype, device=xs_feats.device)\n",
        "        for i, el in enumerate(self.embedding_layers):\n",
        "            psi[:, :-1, i, :] = el(embedding_layer_input[:, :, i, :])\n",
        "        psi[:,:-1,-1,:] = self.tab_encoder(xs_static).unsqueeze(1)\n",
        "        psi[:,-1,:,:] = self.special_embeddings(self.REPRESENTATION_EMBEDDING_KEY.to(self.device)).unsqueeze(0).unsqueeze(1)\n",
        "        mask_inds = torch.cat((xs_feats[:,:,-1] == 1, torch.zeros((xs_feats.shape[0], 1), device=xs_feats.device, dtype=torch.bool)), dim=1)\n",
        "        psi[mask_inds, :, :] = self.special_embeddings(self.MASKED_EMBEDDING_KEY.to(self.device))\n",
        "        if self.predict_events:\n",
        "            psi[event_mask_inds, :] = self.special_embeddings(self.MASKED_EMBEDDING_KEY.to(self.device))\n",
        "\n",
        "        # batch, time step, full embedding\n",
        "        time_embeddings = self.full_time_embedding(xs_times.unsqueeze(2))\n",
        "        time_embeddings = torch.cat((time_embeddings,\n",
        "            self.full_rep_embedding.weight.T.unsqueeze(0).expand(xs_feats.shape[0],-1,-1)),\n",
        "            dim=1)\n",
        "        for layer_i, (event_transformer, time_transformer) in enumerate(zip(self.event_transformers, self.time_transformers)):\n",
        "            et_out_shape = (psi.shape[0], psi.shape[2], psi.shape[1], psi.shape[3])\n",
        "            embeddings = psi.transpose(1,2).flatten(2) + self.full_event_embedding.weight.unsqueeze(0)\n",
        "            event_outs = event_transformer(embeddings).view(et_out_shape).transpose(1,2)\n",
        "            tt_out_shape = event_outs.shape\n",
        "            embeddings = event_outs.flatten(2) + time_embeddings\n",
        "            psi = time_transformer(embeddings).view(tt_out_shape)\n",
        "        transformed = psi.flatten(2)\n",
        "\n",
        "        if self.fusion_method == 'rep_token':\n",
        "            z_ts = transformed[:,-1,:]\n",
        "        elif self.fusion_method == 'masked_embed':\n",
        "            if self.pretrain_masked_steps > 1:\n",
        "                masked_ind = F.pad(xs_feats[:,:,-1] > 0, (0,1), value=False)\n",
        "                z_ts = []\n",
        "                for i in range(transformed.shape[0]):\n",
        "                    z_ts.append(F.pad(transformed[i, masked_ind[i],:], (0,0,0,self.pretrain_masked_steps-masked_ind[i].sum()), value=0.))\n",
        "                z_ts = torch.stack(z_ts) # batch size x pretrain_masked_steps x d_embedding\n",
        "            else:\n",
        "                masked_ind = xs_feats[:,:,-1:]\n",
        "                z_ts = []\n",
        "                for i in range(transformed.shape[0]):\n",
        "                    z_ts.append(transformed[i, torch.nonzero(masked_ind[i].squeeze()==1),:])\n",
        "                z_ts = torch.cat(z_ts, dim=0).squeeze()\n",
        "        elif self.fusion_method == 'averaging':\n",
        "            z_ts = torch.mean(transformed[:,:-1,:], dim=1)\n",
        "\n",
        "        # Return the final output based on the mode\n",
        "        z = z_ts\n",
        "        if representation:\n",
        "            return z\n",
        "        if pretrain:\n",
        "            rep_token_head = torch.tile(transformed[:,0,:].unsqueeze(1), (1, self.masked_transform_timesteps, 1))\n",
        "            y_hat_presence = self.pretrain_presence_proj(z).squeeze() if self.pretrain_presence else None\n",
        "            y_hat_value = self.pretrain_value_proj(z).squeeze(1) if self.pretrain_value else None\n",
        "            z_events = []\n",
        "            y_hat_events, y_hat_events_presence = None, None\n",
        "            if self.predict_events:\n",
        "                for i in range(event_mask_inds.shape[0]):\n",
        "                    z_events.append(psi[i][event_mask_inds[i].nonzero(as_tuple=True)].flatten())\n",
        "                z_events = torch.stack(z_events)\n",
        "                y_hat_events = self.predict_events_proj(z_events).squeeze()\n",
        "                y_hat_events_presence = self.predict_events_presence_proj(z_events).squeeze() if self.pretrain_presence else None\n",
        "            return y_hat_value, y_hat_presence, y_hat_events, y_hat_events_presence\n",
        "        else:\n",
        "            out = self.head(z).squeeze(1)\n",
        "            if self.save_representation:\n",
        "                return out, z\n",
        "            else:\n",
        "                return out\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizers = [torch.optim.AdamW([p for l in self.modules() for p in l.parameters()],\n",
        "                lr=self.lr, weight_decay=self.weight_decay)]\n",
        "        return optimizers\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Unpack the batch data\n",
        "        x, y = batch\n",
        "        y = torch.tensor(y, dtype=torch.float64, device=self.device)\n",
        "        batch_size = y.shape[0]\n",
        "\n",
        "        # Check if the model is in pretraining mode\n",
        "        if self.pretrain:\n",
        "            # Prepare the batch for pretraining\n",
        "            x_pretrain, y, mask, y_events, y_events_mask = self.pretrain_prep_batch(x, batch_size)\n",
        "            # Forward pass for pretraining\n",
        "            y_hat_value, y_hat_presence, y_hat_events, y_hat_events_presence = self.forward(x_pretrain, pretrain=True)\n",
        "\n",
        "            # Initialize the loss\n",
        "            loss = 0\n",
        "            # Calculate the value prediction loss if enabled\n",
        "            if self.pretrain_value:\n",
        "                loss += self.pretrain_loss(y_hat_value * mask, y * mask).mean()\n",
        "            # Calculate the presence prediction loss if enabled\n",
        "            if self.pretrain_presence:\n",
        "                loss += self.pretrain_presence_loss(y_hat_presence, mask).mean() * self.pretrain_presence_weight\n",
        "            # Calculate the event prediction loss if enabled\n",
        "            if self.predict_events:\n",
        "                loss += self.pretrain_loss(y_hat_events * y_events_mask, y_events * y_events_mask).mean()\n",
        "        else:\n",
        "            # Forward pass for standard training\n",
        "            y_hat = self.forward(self.feats_to_input(x, batch_size))\n",
        "            # Calculate the loss with optional class weighting\n",
        "            if self.pos_frac is not None:\n",
        "                weight = torch.where(y > 0, self.pos_weight, self.neg_weight)\n",
        "                loss = self.loss_function(y_hat, y, weight)\n",
        "            else:\n",
        "                loss = self.loss_function(y_hat, y)\n",
        "\n",
        "        # Update metrics and log the training loss\n",
        "        self.train_auroc.update(y_hat, y.to(int))\n",
        "        self.train_ap.update(y_hat, y.to(int))\n",
        "        self.log('train_loss', loss, sync_dist=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "        def validation_step(self, batch, batch_idx):\n",
        "            # Unpack the batch data\n",
        "            x, y = batch\n",
        "            y = torch.tensor(y, dtype=torch.float64, device=self.device)\n",
        "            batch_size = y.shape[0]\n",
        "\n",
        "            # Check if the model is in pretraining mode\n",
        "            if self.pretrain:\n",
        "                # Prepare the batch for pretraining\n",
        "                x_pretrain, y, mask, y_events, y_events_mask = self.pretrain_prep_batch(x, batch_size)\n",
        "                # Forward pass for pretraining\n",
        "                y_hat_value, y_hat_presence, y_hat_events, y_hat_events_presence = self.forward(x_pretrain, pretrain=True)\n",
        "\n",
        "                # Initialize the loss\n",
        "                loss = 0\n",
        "                # Calculate the value prediction loss if pretraining value prediction is enabled\n",
        "                if self.pretrain_value:\n",
        "                    loss += self.calculate_pretrain_loss(y_hat_value, y, mask)\n",
        "                # Calculate the presence prediction loss if pretraining presence prediction is enabled\n",
        "                if self.pretrain_presence:\n",
        "                    presence_loss = self.calculate_pretrain_loss(y_hat_presence, mask, presence_weight=self.pretrain_presence_weight)\n",
        "                    loss += presence_loss\n",
        "                # Calculate the event prediction loss if event prediction is enabled\n",
        "                if self.predict_events:\n",
        "                    event_loss = self.calculate_pretrain_loss(y_hat_events, y_events, y_events_mask)\n",
        "                    loss += event_loss\n",
        "\n",
        "                # Log validation losses\n",
        "                self.log('val_next_loss', loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
        "                if self.pretrain_presence:\n",
        "                    self.log('val_presence_loss', presence_loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
        "                if self.predict_events:\n",
        "                    self.log('val_event_loss', event_loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
        "\n",
        "            else:\n",
        "                # Forward pass for validation\n",
        "                y_hat = self.forward(self.feats_to_input(x, batch_size))\n",
        "                # Calculate and log the validation loss\n",
        "                loss = self.calculate_loss(y_hat, y)\n",
        "                self.log('val_loss', loss, on_epoch=True, sync_dist=True, prog_bar=True, rank_zero_only=True)\n",
        "\n",
        "                # Update and log AUROC and Average Precision metrics\n",
        "                self.val_auroc.update(y_hat, y.to(int).to(self.device))\n",
        "                self.val_ap.update(y_hat, y.to(int).to(self.device))\n",
        "                self.log_metrics('val', self.val_auroc, self.val_ap)\n",
        "\n",
        "            return loss\n",
        "\n",
        "    def training_epoch_end(self, training_step_outputs):\n",
        "        if not self.pretrain:\n",
        "            self.log('train_auroc', self.train_auroc, sync_dist=True, rank_zero_only=True)\n",
        "            self.log('train_ap', self.train_ap, sync_dist=True, rank_zero_only=True)\n",
        "\n",
        "    def validation_epoch_end(self, validation_step_outputs):\n",
        "        if not self.pretrain:\n",
        "            print(\"val_auroc\", self.val_auroc.compute(), \"val_ap\", self.val_ap.compute())\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # Unpack the batch data\n",
        "        x, y = batch\n",
        "        y = torch.tensor(y, dtype=torch.float64, device=self.device)\n",
        "        batch_size = y.shape[0]\n",
        "\n",
        "        # Check if we need to save representations\n",
        "        if self.save_representation:\n",
        "            # Forward pass to get predictions and representations\n",
        "            y_hat, z = self.forward(self.feats_to_input(x, batch_size))\n",
        "            print(\"saving representations...\")\n",
        "            # Save the representations to a file\n",
        "            with open(self.save_representation, 'ab') as f:\n",
        "                # Check if the target is multi-dimensional and save accordingly\n",
        "                if y.ndim == 1:\n",
        "                    np.savetxt(f, np.concatenate([z.cpu(), y.unsqueeze(1).cpu()], axis=1))\n",
        "                else:\n",
        "                    np.savetxt(f, np.concatenate([z.cpu(), y.cpu()], axis=1))\n",
        "        else:\n",
        "            # Forward pass to get predictions\n",
        "            y_hat = self.forward(self.feats_to_input(x, batch_size))\n",
        "\n",
        "        # Calculate loss\n",
        "        if self.pos_frac is not None:\n",
        "            # Apply different weights for positive and negative samples\n",
        "            weight = torch.where(y > 0, self.pos_weight, self.neg_weight)\n",
        "            loss = self.loss_function(y_hat, y, weight)\n",
        "        else:\n",
        "            loss = self.loss_function(y_hat, y)\n",
        "\n",
        "        # Log the test loss\n",
        "        self.log('test_loss', loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
        "\n",
        "        # Update metrics\n",
        "        self.test_auroc.update(y_hat, y.to(int).to(self.device))\n",
        "        self.log('test_auroc', self.test_auroc, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
        "        self.test_ap.update(y_hat, y.to(int).to(self.device))\n",
        "        self.log('test_ap', self.test_ap, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
        "\n",
        "        # Return the loss and metrics for further processing if needed\n",
        "        return loss, self.test_auroc, self.test_ap\n",
        "\n",
        "    def on_load_checkpoint(self, checkpoint):\n",
        "        # Load state dict from the checkpoint\n",
        "        state_dict = checkpoint[\"state_dict\"]\n",
        "        model_state_dict = self.state_dict()\n",
        "\n",
        "        # Initialize a flag to track changes\n",
        "        is_changed = False\n",
        "\n",
        "        # Update model's state dict with checkpoint's state dict\n",
        "        for k in model_state_dict:\n",
        "            if k not in state_dict:\n",
        "                state_dict[k] = model_state_dict[k]\n",
        "                is_changed = True\n",
        "\n",
        "        # Adjust the loaded state dict to match the model's state dict\n",
        "        for k in list(state_dict.keys()):\n",
        "            if k in model_state_dict:\n",
        "                # Skip loading parameters with mismatched shapes, particularly in the 'head' layer\n",
        "                if k.startswith('head') and state_dict[k].shape != model_state_dict[k].shape:\n",
        "                    print(f\"Skip loading parameter: {k}, \"\n",
        "                          f\"required shape: {model_state_dict[k].shape}, \"\n",
        "                          f\"loaded shape: {state_dict[k].shape}\")\n",
        "                    state_dict[k] = model_state_dict[k]\n",
        "                    is_changed = True\n",
        "            else:\n",
        "                # Remove parameters not present in the model's state dict\n",
        "                print(f\"Dropping parameter {k}\")\n",
        "                del state_dict[k]\n",
        "                is_changed = True\n",
        "\n",
        "        # If changes were made, clear optimizer states to avoid conflicts\n",
        "        if is_changed:\n",
        "            checkpoint.pop(\"optimizer_states\", None)\n",
        "\n",
        "        # If the encoder is frozen, ensure its parameters are not updated\n",
        "        if self.freeze_encoder:\n",
        "            self.freeze()\n",
        "\n",
        "    def freeze(self):\n",
        "        print('Freezing')\n",
        "        for n, w in self.named_parameters():\n",
        "            if \"head\" not in n:\n",
        "                w.requires_grad = False\n",
        "            else:\n",
        "                print(\"Skip freezing:\", n)\n"
      ],
      "metadata": {
        "id": "vo-VAhKtwMuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning-Rate Adjustment\n",
        "This is an adjustment that is applied in the initial phase of the training (also known as the warm-up training phase). The task here is to gradually increase the learning rate over a provided number of steps. This is to prevent massive weight updates from the get-go of the training that can lead to divergence or poor convergence."
      ],
      "metadata": {
        "id": "zvfvnv_o9zoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class WarmUpCallback(torch.optim.lr_scheduler._LRScheduler):\n",
        "    \"\"\"\n",
        "    A callback for linearly warming up the learning rate over a specified number of steps.\n",
        "    Optionally applies an inverse square root decay after warmup.\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, warmup_steps, base_lr=None, invsqrt=True, decay=None, last_epoch=-1):\n",
        "        # Initialize the parent class\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "        # Store the warmup steps and base learning rate\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.base_lr = base_lr if base_lr is not None else [group['lr'] for group in optimizer.param_groups]\n",
        "        self.invsqrt = invsqrt  # Whether to apply inverse square root decay\n",
        "        self.decay = decay if decay is not None else warmup_steps  # Decay steps\n",
        "\n",
        "        # Initialize the step counter\n",
        "        self.steps = 0\n",
        "\n",
        "    def set_lr(self, optimizer, lr):\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def on_train_batch_start(self, trainer, model, batch, batch_idx):\n",
        "        # Retrieve the optimizer(s) from the model\n",
        "        optimizers = model.optimizers()\n",
        "\n",
        "        # Check if the warmup phase is still ongoing\n",
        "        if self.state['steps'] < self.warmup_steps:\n",
        "            # If base learning rate is not set, infer it from the optimizer(s)\n",
        "            if self.state['base_lr'] is None:\n",
        "                self.state['base_lr'] = [o.param_groups[0]['lr'] for o in optimizers] if isinstance(optimizers, list) else optimizers.param_groups[0]['lr']\n",
        "\n",
        "            # Calculate the new learning rate based on the current step\n",
        "            new_lr = self.state['steps'] / self.warmup_steps * self.state['base_lr']\n",
        "\n",
        "            # Apply the new learning rate to the optimizer(s)\n",
        "            if isinstance(optimizers, list):\n",
        "                for opt, base_lr in zip(optimizers, self.state['base_lr']):\n",
        "                    self.set_lr(opt, new_lr)\n",
        "            else:\n",
        "                self.set_lr(optimizers, new_lr)\n",
        "\n",
        "        # If warmup is complete and inverse square root scaling is enabled\n",
        "        elif self.invsqrt:\n",
        "            # Calculate the decayed learning rate\n",
        "            decayed_lr = self.state['base_lr'] * (self.decay / (self.state['steps'] - self.warmup_steps + self.decay)) ** 0.5\n",
        "\n",
        "            # Apply the decayed learning rate to the optimizer(s)\n",
        "            if isinstance(optimizers, list):\n",
        "                for opt, base_lr in zip(optimizers, self.state['base_lr']):\n",
        "                    self.set_lr(opt, decayed_lr)\n",
        "            else:\n",
        "                self.set_lr(optimizers, decayed_lr)\n",
        "\n",
        "        # Increment the step counter\n",
        "        self.state['steps'] += 1\n",
        "\n",
        "    # Helper method to set the learning rate for the optimizer(s)\n",
        "    def set_lr(self, optimizer, lr):\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.state.update(state_dict)\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.state.copy()"
      ],
      "metadata": {
        "id": "ySAjUcvv90et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Weight Averaging\n",
        "This is to average the weights of multiple models by averaging them to improve the overall performance here."
      ],
      "metadata": {
        "id": "5G8O5P0m_K6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_models(models):\n",
        "    \"\"\"Averages model weights and loads the resulting weights into the first model, returning it\"\"\"\n",
        "    models = list(models)\n",
        "    n = len(models)\n",
        "    sds = [m.state_dict() for m in models]\n",
        "    averaged = {}\n",
        "    for k in sds[0]:\n",
        "        averaged[k] = sum(sd[k] for sd in sds) / n\n",
        "    models[0].load_state_dict(averaged)\n",
        "    return models[0]"
      ],
      "metadata": {
        "id": "BwOM0LWX_L6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main\n",
        "\n",
        "This is where the main execution happens, from data pre-processing to training, to (in the future) validation as well.\n",
        "\n",
        "This code includes the testing as well. As part of the final project, I will abstract this into a separate module completely."
      ],
      "metadata": {
        "id": "Khrn6CwE_PYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 2020\n",
        "pl.seed_everything(seed)\n",
        "dm = physionet.PhysioNetDataModule(batch_size=512, num_workers=16, use_temp_cache=True)\n",
        "dm.setup()\n",
        "pretrain_model = duett.pretrain_model(d_static_num=dm.d_static_num(),\n",
        "        d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(),\n",
        "        seed=seed)\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(save_last=True, monitor='val_loss', mode='min', save_top_k=1, dirpath='checkpoints')\n",
        "warmup = WarmUpCallback(steps=2000)\n",
        "trainer = pl.Trainer(gpus=1, logger=False, num_sanity_val_steps=2, max_epochs=300,\n",
        "        gradient_clip_val=1.0, callbacks=[warmup, checkpoint])\n",
        "trainer.fit(pretrain_model, dm)\n",
        "\n",
        "pretrained_path = checkpoint.best_model_path\n",
        "for seed in range(2020, 2023):\n",
        "    pl.seed_everything(seed)\n",
        "    fine_tune_model = duett.fine_tune_model(pretrained_path, d_static_num=dm.d_static_num(),\n",
        "            d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(), seed=seed)\n",
        "    checkpoint = pl.callbacks.ModelCheckpoint(save_top_k=5, save_last=False, mode='max', monitor='val_ap', dirpath='checkpoints')\n",
        "    warmup = WarmUpCallback(steps=1000)\n",
        "    trainer = pl.Trainer(gpus=1, logger=False, max_epochs=50, gradient_clip_val=1.0,\n",
        "            callbacks=[warmup, checkpoint])\n",
        "    trainer.fit(fine_tune_model, dm)\n",
        "    final_model = average_models([duett.fine_tune_model(path, d_static_num=dm.d_static_num(),\n",
        "            d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac())\n",
        "            for path in checkpoint.best_k_models.keys()])\n",
        "    trainer.test(final_model, dataloaders=dm)"
      ],
      "metadata": {
        "id": "JYdp1_EZ_P9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "Will be filled in final report.\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison\n",
        "Will be filled in final report.\n"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "Will be filled in final report.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1.   Labach, A., Pokhrel, A., Huang, X. S., Zuberi, S., Yi, S. E., Volkovs, M., ... & Krishnan, R. G. (2023, December). Duett: Dual event time transformer for electronic health records. In Machine Learning for Healthcare Conference (pp. 403-422). PMLR.\n",
        "2. Johnson, A., Bulgarelli, L., Pollard, T., Horng, S., Celi, L. A., & Mark, R. (2023). MIMIC-IV Clinical Database Demo (version 2.2). PhysioNet. https://doi.org/10.13026/dp1f-ex47."
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}