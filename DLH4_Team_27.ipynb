{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1038cd00-630f-4f8f-ac62-1ba625aea2e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Author\n",
    "**Aryan Kukreja**\n",
    "\n",
    "* *Email*: aryansk2@illinois.edu\n",
    "* *UIN*: 652936393\n",
    "* *GitHub Repo*: https://github.com/ABusyProgrammer/CS598-DLH\n",
    "* *Video Link*: https://mediaspace.illinois.edu/media/t/1_a9jzgzkm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78221a9c-a258-4f10-b7e9-5140d8cbbd04",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the rapidly evolving field of healthcare analytics, Electronic Health Records (EHRs) have emerged as a vital resource. These records, which contain a wealth of patient information, hold the potential to significantly improve patient outcomes and optimize the allocation of healthcare resources. However, the inherent complexity of EHRs, characterized by high sparsity and irregular observations, presents a formidable challenge. Traditional time series analysis methods, designed for densely sampled data, often fall short when applied to EHRs. While state-of-the-art methods such as the various categories and implementations of neural network models and attention mechanisms have shown promising results, they come with their own set of limitations. These methods often necessitate substantial computational resources and involve truncating inputs, which can compromise the accuracy of the predictions.\n",
    "\n",
    "Addressing these challenges, this paper introduces a groundbreaking approach with the Dual Event Time Transformer (DuETT). DuETT represents a significant departure from traditional methods, offering an innovative architecture that attends to both the time and event type dimensions of EHR data. This unique capability allows DuETT to transform sparse time series into a regular sequence, thereby enabling the application of larger and deeper neural networks. This transformation process, which is at the heart of DuETT’s innovation, effectively handles the irregularity and sparsity of EHR data. The effectiveness of DuETT is not just theoretical; it has been empirically demonstrated. DuETT outperforms state-of-the-art deep learning models on multiple downstream tasks using the MIMIC-IV and PhysioNet-2012 EHR datasets. By providing a robust and effective representation of EHR data, DuETT makes a significant contribution to the field of healthcare analytics. Its state-of-the-art performance and potential for practical applications in hospitals underscore the importance and relevance of this research in the ongoing efforts to leverage EHRs for improved healthcare outcomes.\n",
    "\n",
    "## Resources\n",
    "Paper Being Analyzed: [DuETT: Dual Event Time Transformer for Electronic Health\n",
    "Records](https://arxiv.org/pdf/2304.13017.pdf)\n",
    "\n",
    "Original Code From the Author: [DuETT GitHub Repository](https://github.com/layer6ai-labs/DuETT/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bfd40-dbc0-48cf-89de-476bc7355aad",
   "metadata": {},
   "source": [
    "## Scope of Reproducibility:\n",
    "The following are some of the key hypothesis that this paper looks to test:\n",
    "1. **Capture EHR Structure**: If DuETT attends over both time and event dimensions of EHR data, then it can produce robust representations that capture the structure of EHR data.\n",
    "2. **Handle Sparsity and Irregularity**: If DuETT transforms sparse and irregularly sampled time series into regular sequences with fixed length, then it can reduce computational complexity and handle the sparsity and irregularity of EHR data.\n",
    "3. **Improve Model Performance**: If DuETT is applied to multiple downstream tasks using the MIMIC-IV and PhysioNet-2012 EHR datasets, then it can outperform state-of-the-art deep learning models.\n",
    "4. **Leverage Self-Supervised Learning**: If DuETT utilizes self-supervised prediction tasks for model pre-training, then it can enable the training of larger models with limited labeled data.\n",
    "\n",
    "These hypotheses form the basis of the paper’s investigation into the effectiveness of the DuETT architecture for modeling EHR data. Each hypothesis is designed to test a specific aspect of DuETT’s capabilities and its potential advantages over existing methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c79bbc-d968-40f8-97ae-438e9776db42",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "The following section has a step-by-step implementation of the given paper. Section headers are named based on the grading [**rubric**](https://docs.google.com/document/d/1ftHUFl_eeZNfRYLNI0jh-v8tvkQfvSz-q8jzt2026k8/edit#heading=h.gjdgxs) provided in Piazza to make it easier to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8df7ea-b3e4-42fb-8b78-fecf52873bcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Environment\n",
    "\n",
    "Although this notebook is shared via Google Collab, the actual training, testing and validation of the implementation code was performed under an AWS SageMaker instance. This is because the training required a more powerful processor with larger memory, and I was only able to get a more powerful machine via AWS (I work at Amazon, so its free for me). \n",
    "\n",
    "Specifically, the hardware that worked for me was the `ml.r7i.2xlarge` ML processor provided by Amazon SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751c13e-bf0c-4bc2-b5dd-51db3f37ba92",
   "metadata": {},
   "source": [
    "#### Required Packages\n",
    "These are the packages sourced from the DuETT project's [requirements.txt](https://github.com/layer6ai-labs/DuETT/blob/master/requirements.txt) file. That file's versions are compatible specifically with Python 3.8.5; to ensure that this project is runnable across any Python version, I've removed the specific versions from the pip installation instructions below; this resulted in a need to refactor portions of the code.\n",
    "\n",
    "***Python 3.10.3*** (the latest currently available in AWS Sagemaker) was used for my project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fb3047-c69f-4916-9b93-0f1dca81c564",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-2.2.4-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytorch-lightning) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Using cached torchmetrics-1.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytorch-lightning) (4.9.0)\n",
      "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
      "  Using cached lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (69.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n",
      "Using cached pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
      "Using cached lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Using cached torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, lightning-utilities, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 lightning-utilities-0.11.2 multidict-6.0.5 pytorch-lightning-2.2.4 torchmetrics-1.3.2 yarl-1.9.4\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchaudio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchaudio) (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch->torchaudio) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n",
      "Collecting x-transformers\n",
      "  Using cached x_transformers-1.28.5-py3-none-any.whl.metadata (661 bytes)\n",
      "Requirement already satisfied: torch>=1.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from x-transformers) (2.1.0)\n",
      "Collecting einops>=0.7.0 (from x-transformers)\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6->x-transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6->x-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6->x-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6->x-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6->x-transformers) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.6->x-transformers) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.6->x-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
      "Using cached x_transformers-1.28.5-py3-none-any.whl (35 kB)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: einops, x-transformers\n",
      "Successfully installed einops-0.8.0 x-transformers-1.28.5\n",
      "Collecting torchtime\n",
      "  Using cached torchtime-0.6.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchtime) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchtime) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchtime) (1.4.1.post1)\n",
      "Collecting sktime<0.19,>=0.17 (from torchtime)\n",
      "  Using cached sktime-0.18.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting torch<2.1,>=1.12 (from torchtime)\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchtime) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.27.1->torchtime) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.27.1->torchtime) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.27.1->torchtime) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.27.1->torchtime) (2024.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.1->torchtime) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.1->torchtime) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.1->torchtime) (3.3.0)\n",
      "Collecting deprecated>=1.2.13 (from sktime<0.19,>=0.17->torchtime)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy<2.0,>=1.21 (from torchtime)\n",
      "  Using cached numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sktime<0.19,>=0.17->torchtime) (1.5.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sktime<0.19,>=0.17->torchtime) (21.3)\n",
      "Collecting scikit-base<0.5.0 (from sktime<0.19,>=0.17->torchtime)\n",
      "  Using cached scikit_base-0.4.6-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting scikit-learn<2.0,>=1.1 (from torchtime)\n",
      "  Using cached scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.1,>=1.12->torchtime) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.1,>=1.12->torchtime) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.1,>=1.12->torchtime) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.1,>=1.12->torchtime) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.1,>=1.12->torchtime) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch<2.1,>=1.12->torchtime)\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=1.12->torchtime) (69.1.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=1.12->torchtime) (0.42.0)\n",
      "Collecting cmake (from triton==2.0.0->torch<2.1,>=1.12->torchtime)\n",
      "  Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting lit (from triton==2.0.0->torch<2.1,>=1.12->torchtime)\n",
      "  Using cached lit-18.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.13->sktime<0.19,>=0.17->torchtime)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas<2.0.0,>=1.1.0->sktime<0.19,>=0.17->torchtime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas<2.0.0,>=1.1.0->sktime<0.19,>=0.17->torchtime) (2024.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch<2.1,>=1.12->torchtime) (2.1.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->sktime<0.19,>=0.17->torchtime) (3.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch<2.1,>=1.12->torchtime) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.1.0->sktime<0.19,>=0.17->torchtime) (1.16.0)\n",
      "Using cached torchtime-0.6.1-py3-none-any.whl (23 kB)\n",
      "Using cached sktime-0.18.1-py3-none-any.whl (17.0 MB)\n",
      "Using cached numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Using cached scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached scikit_base-0.4.6-py3-none-any.whl (119 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "Using cached lit-18.1.4-py3-none-any.whl (96 kB)\n",
      "Installing collected packages: lit, wrapt, scikit-base, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, deprecated, scikit-learn, sktime, triton, torch, torchtime\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.4.1.post1\n",
      "    Uninstalling scikit-learn-1.4.1.post1:\n",
      "      Successfully uninstalled scikit-learn-1.4.1.post1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "Successfully installed cmake-3.29.2 deprecated-1.2.14 lit-18.1.4 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 scikit-base-0.4.6 scikit-learn-1.2.2 sktime-0.18.1 torch-2.0.1 torchtime-0.6.1 triton-2.0.0 wrapt-1.16.0\n",
      "Requirement already satisfied: torchmetrics in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchmetrics) (1.24.4)\n",
      "Requirement already satisfied: packaging>17.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchmetrics) (0.11.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2.0.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.42.0)\n",
      "Requirement already satisfied: cmake in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->torchmetrics) (3.29.2)\n",
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->torchmetrics) (18.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip freeze > reqs.txt\n",
    "# !cat reqs.txt | xargs -n 1 pip uninstall -y\n",
    "\n",
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install pytorch-lightning\n",
    "!pip install torch\n",
    "!pip install torchaudio\n",
    "!pip install torchvision\n",
    "!pip install x-transformers\n",
    "!pip install torchtime\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ce6ba-5261-4344-8cdb-3f754d070ea6",
   "metadata": {},
   "source": [
    "#### Import Installed Dependencies\n",
    "Once the above packages are installed, we need to import the relevant dependencies. I've collected all imports across the various `.py` files in the [DuETT]() project into a single code-block for easier reading, and have annotated them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32d0a328-96a6-49c1-91db-445284f53a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from multiprocessing import Manager\n",
    "import argparse\n",
    "\n",
    "# Third-party library imports for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Core PyTorch packages for neural network operations and multiprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# PyTorch utility for data loading\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# PyTorch Lightning is a high-level wrapper for PyTorch that aids in organizing code for training\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Torchmetrics is a PyTorch library for various machine learning metrics\n",
    "import torchmetrics\n",
    "\n",
    "# X-Transformers is a PyTorch-based library for transformer models\n",
    "import x_transformers\n",
    "\n",
    "# Torchtime is a PyTorch-based library for time series analysis. The data we import here is the MIMIC-IV dataset.\n",
    "from torchtime.data import PhysioNet2012"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f78b4-69c2-4bb2-90d5-1a259dc758c9",
   "metadata": {},
   "source": [
    "### Data\n",
    "For this notebook, the dataset was already implemented in the code block from the above section, as:\n",
    "\n",
    "```python\n",
    "from torchtime.data import PhysioNet2012\n",
    "```\n",
    "This will be used in the below data-model.\n",
    "\n",
    "#### Physionet2012 Data-Set\n",
    "For this paper, we rely on the dataset used from the [Physionet in Cardiology Challenge](https://physionet.org/content/challenge-2012/1.0.0/) from 2012, also abbreviated `Physionet2012`. The dataset contains data from ~8,000 patients spread across ~12,000 ICU stays due to various cardiac-related root-causes. \n",
    "\n",
    "Compared to the main MIMIC-IV data-set that has data spanning 2008 to 2019, this dataset is much smaller, and it has been selected by the authors of this paper for a reason: real-life electronic health-record (EHR) applications have far smaller labelled data-sets. Given that the objective of this paper is to leverage self-supervised learning (SSL) to train models using limited-sized data-sets, relying on Physionet2012 as a data-set suits the approach of this paper.\n",
    "\n",
    "The following are the entries of each record:\n",
    "1. **General Descriptors**: Collected at the time of admission, these include data such as *Age*, *Gender*, and *Weight*; all of which tie back to identifying the patient who was admitted into the ICU. A total of 6 such fields exist. \n",
    "2. **Time-Series Data**. Recorded in the first 48 hours since admission, these are a set of 42 descriptors. Of these 42, at least 1 of them must be defined per record along with a `timestamp` defining exactly when the observation was made. For the same patient's same visit to the ICU, we can have multiple readings of a given time-series descriptor across different timestamps. \n",
    "3. ***Outcome-Related Descriptors**: These are descriptors that record the outcome of the patient's visit to the ICU, after their stay is complete. It includes 6 variables, such as *length of stay*, *survival*, and *record ID*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726b102-7c73-41ce-974c-d1b64d0c73cc",
   "metadata": {},
   "source": [
    "#### Data Model\n",
    "\n",
    "The first step is to define the model of the data that will be used throughout the training process. these classes serve as wrappers over the core `Physionet2012` class that is imported to retrieve all the data that will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cbcb3a5-11bb-44f4-b1cf-8b1605bb3592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PhysioNetDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A PyTorch Dataset for the PhysioNet 2012 data.\"\"\"\n",
    "\n",
    "    def __init__(self, split_name, n_timesteps=32, use_temp_cache=False, **kwargs):\n",
    "        \"\"\"Initialize the dataset with given parameters.\"\"\"\n",
    "        self.split_name = split_name\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.temp_cache = Manager().dict() if use_temp_cache else None\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Prepare the data for the dataset.\"\"\"\n",
    "        # Load the data\n",
    "        tt_data = PhysioNet2012(self.split_name, train_prop=0.7, val_prop=0.15, time=False, seed=0)\n",
    "\n",
    "        # Split the data into features and labels\n",
    "        self.X, self.y = tt_data.X, tt_data.y\n",
    "\n",
    "        # Calculate the statistics of the features\n",
    "        self.means, self.stds, self.maxes, self.mins = [], [], [], []\n",
    "        for i in range(self.X.shape[2]):\n",
    "            vals = self.X[:, :, i].flatten()\n",
    "            vals = vals[~torch.isnan(vals)]\n",
    "            self.means.append(vals.mean())\n",
    "            self.stds.append(vals.std())\n",
    "            self.maxes.append(vals.max())\n",
    "            self.mins.append(vals.min())\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples in the dataset.\"\"\"\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Get a sample from the dataset.\"\"\"\n",
    "        # If the sample is in the cache, return it\n",
    "        if self.temp_cache is not None and i in self.temp_cache:\n",
    "            return self.temp_cache[i]\n",
    "\n",
    "        # Prepare the input features\n",
    "        ins = self.X[i, ~torch.isnan(self.X[i, :, 0]), :]\n",
    "        time = ins[:, 0] / 60 / 24\n",
    "        x_static = torch.zeros(self.d_static_num())\n",
    "        x_ts = torch.zeros((self.n_timesteps, self.d_time_series_num() * 2))\n",
    "\n",
    "        # Process the time-series data\n",
    "        for i_t, t in enumerate(time):\n",
    "            bin = self.n_timesteps - 1 if t == time[-1] else int(t / time[-1] * self.n_timesteps)\n",
    "            for i_ts in range(1, 37):\n",
    "                x_i = ins[i_t, i_ts]\n",
    "                if not torch.isnan(x_i).item():\n",
    "                    x_ts[bin, i_ts - 1] = (x_i - self.means[i_ts]) / (self.stds[i_ts] + 1e-7)\n",
    "                    x_ts[bin, i_ts - 1 + self.d_time_series_num()] += 1\n",
    "\n",
    "        # Process the static data\n",
    "        bin_ends = torch.arange(1, self.n_timesteps + 1) / self.n_timesteps * time[-1]\n",
    "        for i_tab in range(37, 45):\n",
    "            x_i = ins[0, i_tab]\n",
    "            x_i = (x_i - self.means[i_tab]) / (self.stds[i_tab] + 1e-7)\n",
    "            x_static[i_tab - 37] = x_i.nan_to_num(0.)\n",
    "\n",
    "        # Prepare the final input and output data\n",
    "        x = (x_ts, x_static, bin_ends)\n",
    "        y = self.y[i, 0]\n",
    "\n",
    "        # Cache the data if needed\n",
    "        if self.temp_cache is not None:\n",
    "            self.temp_cache[i] = (x, y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def d_static_num(self):\n",
    "        \"\"\"Return the total dimension of numeric static features.\"\"\"\n",
    "        return 8\n",
    "\n",
    "    def d_time_series_num(self):\n",
    "        \"\"\"Return the total dimension of numeric time-series features.\"\"\"\n",
    "        return 36\n",
    "\n",
    "    def d_target(self):\n",
    "        \"\"\"Return the dimension of the target variable.\"\"\"\n",
    "        return 1\n",
    "\n",
    "    def pos_frac(self):\n",
    "        \"\"\"Return the fraction of positive samples in the dataset.\"\"\"\n",
    "        return self.y.mean().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970de7d-72e6-4d7b-9dd7-f02689a8d57f",
   "metadata": {},
   "source": [
    "#### Collation Function\n",
    "This is just a helper method that is used to zip data into sequences. It is used in the Dataloader that is eventually used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "333cfe77-36a6-473a-ba92-3a10786affcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to collate data into sequences\n",
    "def collate_into_seqs(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    return zip(*xs), ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691edf6-8498-452b-aa7d-e1fbfe03d164",
   "metadata": {},
   "source": [
    "#### Data Module\n",
    "This is the actual data module that builds atop the dataset class. In addition to the `PhysionetDataset` class, it adds dats setup functionality for the training process, as well as functions to log training progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db7112f1-d48b-4712-b200-fb1d38443330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch Lightning DataModule for PhysioNet data\n",
    "class PhysioNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, use_temp_cache=False, batch_size=8, num_workers=1, prefetch_factor=2, verbose=0, **kwargs):\n",
    "        \"\"\"Initialize the data module with given parameters.\"\"\"\n",
    "        self.use_temp_cache = use_temp_cache\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.prefetch_factor = prefetch_factor\n",
    "\n",
    "        # Create datasets for training, validation, and testing\n",
    "        self.ds_train = PhysioNetDataset('train', use_temp_cache=use_temp_cache)\n",
    "        self.ds_val = PhysioNetDataset('val', use_temp_cache=use_temp_cache)\n",
    "        self.ds_test = PhysioNetDataset('test', use_temp_cache=use_temp_cache)\n",
    "\n",
    "        self.prepare_data_per_node = False\n",
    "        self.allow_zero_length_dataloader_with_multiple_devices: bool = False\n",
    "\n",
    "        # Arguments for the data loader\n",
    "        self.dl_args = {\n",
    "            'batch_size': self.batch_size,\n",
    "            'prefetch_factor': self.prefetch_factor,\n",
    "            'collate_fn': collate_into_seqs,\n",
    "            'num_workers': num_workers\n",
    "        }\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Prepare the data for the given stage.\"\"\"\n",
    "        if stage is None:\n",
    "            # If no stage is specified, setup data for all stages\n",
    "            self.ds_train.setup()\n",
    "            self.ds_val.setup()\n",
    "            self.ds_test.setup()\n",
    "        elif stage == 'fit':\n",
    "            # If the stage is 'fit', setup data for training and validation\n",
    "            self.ds_train.setup()\n",
    "            self.ds_val.setup()\n",
    "        elif stage == 'validate':\n",
    "            # If the stage is 'validate', setup data for validation\n",
    "            self.ds_val.setup()\n",
    "        elif stage == 'test':\n",
    "            # If the stage is 'test', setup data for testing\n",
    "            self.ds_test.setup()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare the data. This method is intentionally left empty.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _log_hyperparams(self):\n",
    "        \"\"\"Log hyperparameters. This method is intentionally left empty.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Return a data loader for the training data.\"\"\"\n",
    "        return DataLoader(self.ds_train, shuffle=True, **self.dl_args)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Return a data loader for the validation data.\"\"\"\n",
    "        return DataLoader(self.ds_val, **self.dl_args)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"Return a data loader for the testing data.\"\"\"\n",
    "        return DataLoader(self.ds_test, **self.dl_args)\n",
    "\n",
    "    def d_static_num(self):\n",
    "        \"\"\"Return the total dimension of numeric static features.\"\"\"\n",
    "        return self.ds_train.d_static_num()\n",
    "\n",
    "    def d_time_series_num(self):\n",
    "        \"\"\"Return the total dimension of numeric time-series features.\"\"\"\n",
    "        return self.ds_train.d_time_series_num()\n",
    "\n",
    "    def d_target(self):\n",
    "        \"\"\"Return the dimension of the target variable.\"\"\"\n",
    "        return self.ds_train.d_target()\n",
    "\n",
    "    def pos_frac(self):\n",
    "        \"\"\"Return the fraction of positive samples in the dataset.\"\"\"\n",
    "        return self.ds_train.pos_frac()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b810c3-11ef-47cf-a938-a6bb4f059b54",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "With the necessary packages installed and set up, the implementation of this project can begin. The below sections define the structure of the model, including the multi-layer perceptron (MLP) which will be used as an **Embedding Layer** throughout the model.\n",
    "\n",
    "#### Model Structures\n",
    "There is no pre-trained model; the model is defined from scratch (down to the multi-layer perceptron) within this code. At a high-level, the following is the model definition:\n",
    "\n",
    "1. **Special Embeddings**: This is an embedding layer for special timesteps, such as masked, static, [CLS], etc. It's defined as `nn.Embedding(8, d_embedding)`.\n",
    "2. **Embedding Layers**: These are the embedding layers for each time series. They are defined using a list comprehension to create a `nn.ModuleList` of `simple_mlp` layers.\n",
    "3. **Observation Embedding**: This is an embedding layer for observations, defined as `nn.Embedding(16, 1)`.\n",
    "4. **Event Transformers**: These are transformer layers specifically for events. They are defined using a list comprehension to create a `nn.ModuleList` of `x_transformers.Encoder` layers.\n",
    "5. **Full Event Embedding**: This is an embedding layer for the full event, defined as `nn.Embedding(d_time_series_num + 1, et_dim)`.\n",
    "6. **Time Transformers**: These are transformer layers specifically for time. They are defined using a list comprehension to create a `nn.ModuleList` of `x_transformers.Encoder` layers.\n",
    "7. **Full Time Embedding**: This is an embedding layer for the full time, defined as `self.cve(batch_norm=True, d_embedding=tt_dim)`.\n",
    "8. **Full Representation Embedding**: This is an embedding layer for the full representation, defined as `nn.Embedding(tt_dim, 1)`.\n",
    "9. **Head for Prediction**: This is the final prediction layer, defined as a `simple_mlp` layer.\n",
    "10. **Pretraining Value Projection**: This is a projection layer for pretraining values, defined as a `simple_mlp` layer.\n",
    "11. **Pretraining Presence Projection**: This is a projection layer for pretraining presence, defined as a `simple_mlp` layer if `self.pretrain_presence` is True.\n",
    "12. **Event Prediction Projection**: This is a projection layer for event prediction, defined as a `simple_mlp` layer if `self.predict_events` is True.\n",
    "\n",
    "#### Resources\n",
    "1. Paper Being Analyzed: [DuETT: Dual Event Time Transformer for Electronic Health\n",
    "Records](https://arxiv.org/pdf/2304.13017.pdf)\n",
    "2. Original Code From the Author: [DuETT GitHub Repository](https://github.com/layer6ai-labs/DuETT/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1652b19-427c-4d0d-8aa5-354bc2f8480d",
   "metadata": {},
   "source": [
    "#### Defining the Multi-Layer Perceptron\n",
    "This is where we define the mulit-layer perceptron that is used as the embedding layers of the final model that will be tested throughout this code. The last dimension of the MLP tensor has batch-normalization applied to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b9e2c22-32ad-4d1e-b637-3a765ecceecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNormLastDim(nn.Module):\n",
    "    \"\"\"A PyTorch Module for applying Batch Normalization to the last dimension of a tensor.\"\"\"\n",
    "\n",
    "    def __init__(self, d, **kwargs):\n",
    "        \"\"\"Initialize the module with given parameters.\"\"\"\n",
    "        super().__init__()\n",
    "        # Create a 1D BatchNorm layer with 'd' features\n",
    "        self.batch_norm = nn.BatchNorm1d(d, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply the BatchNorm layer to the input tensor.\"\"\"\n",
    "        match x.ndim:\n",
    "            case 2:\n",
    "                # If the input is a 2D tensor, apply BatchNorm directly\n",
    "                return self.batch_norm(x)\n",
    "            case 3:\n",
    "                # If the input is a 3D tensor, transpose the last two dimensions and apply BatchNorm, and then transpose back\n",
    "                return self.batch_norm(x.transpose(1, 2)).transpose(1, 2)\n",
    "            case _:\n",
    "                # If the input is not a 2D or 3D tensor, raise an error\n",
    "                raise NotImplementedError(\"BatchNormLastDim not implemented for ndim > 3 or < 2 yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d069253-bcdd-450d-9575-59bf871c1fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_mlp(d_in, d_out, n_hidden, d_hidden, final_activation=False, input_batch_norm=False,\n",
    "               hidden_batch_norm=False, dropout=0., activation=nn.ReLU):\n",
    "    \"\"\"A simple Multi-Layer Perceptron (MLP) implementation in PyTorch.\"\"\"\n",
    "\n",
    "    # Initialize the list of layers\n",
    "    layers = []\n",
    "\n",
    "    # If there are no hidden layers, create a single linear layer\n",
    "    if n_hidden == 0:\n",
    "        if input_batch_norm:\n",
    "            layers.append(BatchNormLastDim(d_in))\n",
    "        layers.append(nn.Linear(d_in, d_out))\n",
    "    else:\n",
    "        # If there are hidden layers, create them with optional batch normalization and dropout\n",
    "        if input_batch_norm:\n",
    "            layers.append(BatchNormLastDim(d_in))\n",
    "        layers.extend([nn.Linear(d_in, d_hidden), activation(), nn.Dropout(dropout)])\n",
    "\n",
    "        for _ in range(n_hidden - 1):\n",
    "            if hidden_batch_norm:\n",
    "                layers.append(BatchNormLastDim(d_hidden))\n",
    "            layers.extend([nn.Linear(d_hidden, d_hidden), activation(), nn.Dropout(dropout)])\n",
    "\n",
    "        if hidden_batch_norm:\n",
    "            layers.append(BatchNormLastDim(d_hidden))\n",
    "        layers.append(nn.Linear(d_hidden, d_out))\n",
    "\n",
    "    # If final activation is required, add it to the layers\n",
    "    if final_activation:\n",
    "        layers.append(activation())\n",
    "\n",
    "    # Return the MLP as a sequential model\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8805bbd-5c2b-4e55-bb20-365ed50ad811",
   "metadata": {},
   "source": [
    "#### Defining the Model\n",
    "This is where we define the actual model itself. The components defined above (the `PhysionetDataModule`, `simple_mlp`, etc...) will be applied. This is the main model class that defines the key training functions/methods such as `forward()`. It is a PyTorch Lightning module designed for training and evaluating a machine learning model for time-series data analysis that is being conducted here to eveluate the DuETT approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea9e0e17-2904-4424-9db3-3ff1ee4d00ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    \"\"\"A PyTorch Lightning Module for a transformer-based model.\"\"\"\n",
    "\n",
    "    def __init__(self, d_static_num, d_time_series_num, d_target, lr=3.e-4, weight_decay=1.e-1, glu=False,\n",
    "                 scalenorm=True, n_hidden_mlp_embedding=1, d_hidden_mlp_embedding=64, d_embedding=24, \n",
    "                 d_feedforward=512, max_len=48, n_transformer_head=2, n_duett_layers=2, \n",
    "                 d_hidden_tab_encoder=128, n_hidden_tab_encoder=1, norm_first=True, \n",
    "                 fusion_method='masked_embed', n_hidden_head=1, d_hidden_head=64, aug_noise=0., \n",
    "                 aug_mask=0., pretrain=True, pretrain_masked_steps=1, pretrain_n_hidden=0, \n",
    "                 pretrain_d_hidden=64, pretrain_dropout=0.5, pretrain_value=True, \n",
    "                 pretrain_presence=True, pretrain_presence_weight=0.2, predict_events=True,\n",
    "                 transformer_dropout=0., pos_frac=None, freeze_encoder=False, seed=0, \n",
    "                 save_representation=None, masked_transform_timesteps=32, **kwargs):\n",
    "        \"\"\"Initialize the model with given parameters.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Set up hyperparameters\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.d_time_series_num = d_time_series_num\n",
    "        self.d_target = d_target\n",
    "        self.d_embedding = d_embedding\n",
    "        self.max_len = max_len\n",
    "        self.pretrain = pretrain\n",
    "        self.pretrain_masked_steps = pretrain_masked_steps\n",
    "        self.pretrain_dropout = pretrain_dropout\n",
    "        self.freeze_encoder = freeze_encoder\n",
    "        self.set_pos_frac(pos_frac)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.aug_noise = aug_noise\n",
    "        self.aug_mask = aug_mask\n",
    "        self.fusion_method = fusion_method\n",
    "        self.pretrain_presence = pretrain_presence\n",
    "        self.pretrain_presence_weight = pretrain_presence_weight\n",
    "        self.predict_events = predict_events\n",
    "        self.masked_transform_timesteps = masked_transform_timesteps\n",
    "        self.pretrain_value = pretrain_value\n",
    "        self.save_representation = save_representation\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        # Register buffers for multi-GPU training\n",
    "        self.register_buffer(\"MASKED_EMBEDDING_KEY\", torch.tensor(0))\n",
    "        self.register_buffer(\"REPRESENTATION_EMBEDDING_KEY\", torch.tensor(1))\n",
    "\n",
    "        # Set up special embeddings for any special timesteps, e.g., masked, static, [CLS], etc.\n",
    "        self.special_embeddings = nn.Embedding(8, d_embedding)\n",
    "\n",
    "        # Set up embedding layers\n",
    "        self.embedding_layers = nn.ModuleList([\n",
    "            simple_mlp(2, d_embedding, n_hidden_mlp_embedding, d_hidden_mlp_embedding, hidden_batch_norm=True)\n",
    "            for _ in range(d_time_series_num)])\n",
    "\n",
    "        # Set up observation embedding\n",
    "        self.n_obs_embedding = nn.Embedding(16, 1)\n",
    "\n",
    "        # Set up feedforward dimension if not provided\n",
    "        if d_feedforward is None:\n",
    "            d_feedforward = d_embedding * 4\n",
    "\n",
    "        # Set up event transformer dimensions\n",
    "        et_dim = d_embedding * (masked_transform_timesteps + 1)\n",
    "        tt_dim = d_embedding * (d_time_series_num + 1)\n",
    "\n",
    "        # Set up event transformers\n",
    "        self.event_transformers = nn.ModuleList([x_transformers.Encoder(dim=et_dim, depth=1,\n",
    "                heads=n_transformer_head, pre_norm=norm_first, use_scalenorm=scalenorm,\n",
    "                attn_dim_head=d_embedding // n_transformer_head, ff_glu=glu,\n",
    "                ff_mult=d_feedforward / et_dim, attn_dropout=transformer_dropout,\n",
    "                ff_dropout=transformer_dropout) for _ in range(n_duett_layers)])\n",
    "\n",
    "        # Set up full event embedding\n",
    "        self.full_event_embedding = nn.Embedding(d_time_series_num + 1, et_dim)\n",
    "\n",
    "        # Set up time transformers\n",
    "        self.time_transformers = nn.ModuleList([x_transformers.Encoder(dim=tt_dim, depth=1,\n",
    "                heads=n_transformer_head, pre_norm=norm_first, use_scalenorm=scalenorm,\n",
    "                attn_dim_head=d_embedding // n_transformer_head, ff_glu=glu,\n",
    "                ff_mult=d_feedforward / tt_dim, attn_dropout=transformer_dropout,\n",
    "                ff_dropout=transformer_dropout) for _ in range(n_duett_layers)])\n",
    "\n",
    "        # Set up full time embedding\n",
    "        self.full_time_embedding =  self.cve(batch_norm=True, d_embedding=tt_dim)\n",
    "\n",
    "        # Set up full representation embedding\n",
    "        self.full_rep_embedding = nn.Embedding(tt_dim, 1)\n",
    "\n",
    "        # Set up representation dimension\n",
    "        d_representation = d_embedding * (d_time_series_num + 1)  # time_series + static\n",
    "\n",
    "        # Set up head for prediction\n",
    "        self.head = simple_mlp(d_representation, d_target, n_hidden_head, d_hidden_head,\n",
    "                               hidden_batch_norm=True, final_activation=False, activation=nn.ReLU)\n",
    "\n",
    "        # Set up pretraining value projection\n",
    "        self.pretrain_value_proj = simple_mlp(d_representation, d_time_series_num,\n",
    "                                              pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
    "\n",
    "        # Set up pretraining presence projection if needed\n",
    "        if self.pretrain_presence:\n",
    "            self.pretrain_presence_proj = simple_mlp(d_representation, d_time_series_num,\n",
    "                                                     pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
    "\n",
    "        # Set up event prediction projection if needed\n",
    "        if self.predict_events:\n",
    "            self.predict_events_proj = simple_mlp(et_dim, masked_transform_timesteps,\n",
    "                                                  pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
    "            if self.pretrain_presence:\n",
    "                self.predict_events_presence_proj = simple_mlp(et_dim, masked_transform_timesteps,\n",
    "                                                               pretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
    "\n",
    "        # Set up tabular encoder\n",
    "        self.tab_encoder = simple_mlp(d_static_num, d_embedding, n_hidden_tab_encoder,\n",
    "                                      d_hidden_tab_encoder, hidden_batch_norm=True)\n",
    "\n",
    "        # Set up loss functions\n",
    "        self.pretrain_loss = F.mse_loss\n",
    "        self.loss_function = F.binary_cross_entropy_with_logits\n",
    "        self.pretrain_presence_loss = F.binary_cross_entropy_with_logits\n",
    "\n",
    "        # Set up metrics\n",
    "        num_classes = None if d_target == 1 else d_target\n",
    "        task = 'binary' if d_target == 1 else 'multiclass'\n",
    "        self.train_auroc = torchmetrics.AUROC(num_classes=num_classes, task=task)\n",
    "        self.val_auroc = torchmetrics.AUROC(num_classes=num_classes, task=task)\n",
    "        self.train_ap = torchmetrics.AveragePrecision(num_classes=num_classes, task=task)\n",
    "        self.val_ap = torchmetrics.AveragePrecision(num_classes=num_classes, task=task)\n",
    "        self.test_auroc = torchmetrics.AUROC(num_classes=num_classes, task=task)\n",
    "        self.test_ap = torchmetrics.AveragePrecision(num_classes=num_classes, task=task)\n",
    "\n",
    "    def set_pos_frac(self, pos_frac):\n",
    "        \"\"\"Set the fraction of positive samples in the dataset.\"\"\"\n",
    "        if type(pos_frac) == list:\n",
    "            pos_frac = torch.tensor(pos_frac, device=torch.device('cuda'))\n",
    "        self.pos_frac = pos_frac\n",
    "        if pos_frac is not None:\n",
    "            self.pos_weight = 1 / (2 * pos_frac)\n",
    "            self.neg_weight = 1 / (2 * (1 - pos_frac))\n",
    "\n",
    "    def cve(self, d_embedding=None, batch_norm=False):\n",
    "        \"\"\"Create a simple MLP with a single hidden layer and optional batch normalization.\"\"\"\n",
    "        if d_embedding is None:\n",
    "            d_embedding = self.d_embedding\n",
    "        d_hidden = int(np.sqrt(d_embedding))\n",
    "        if batch_norm:\n",
    "            return nn.Sequential(nn.Linear(1, d_hidden), nn.Tanh(), BatchNormLastDim(d_hidden), nn.Linear(d_hidden, d_embedding))\n",
    "        return nn.Sequential(nn.Linear(1, d_hidden), nn.Tanh(), nn.Linear(d_hidden, d_embedding))\n",
    "\n",
    "    def feats_to_input(self, x, batch_size, limits=None):\n",
    "        \"\"\"Prepare the input features for the model.\"\"\"\n",
    "        xs_ts, xs_static, times = x\n",
    "        xs_ts = list(xs_ts)\n",
    "\n",
    "        # Process each time series in the batch\n",
    "        for i, f in enumerate(xs_ts):\n",
    "            n_vars = f.shape[1] // 2\n",
    "            if f.shape[0] > self.max_len:\n",
    "                f = f[-self.max_len:]\n",
    "                times[i] = times[i][-self.max_len:]\n",
    "            # Apply augmentation if needed\n",
    "            if self.training and self.aug_noise > 0 and not self.pretrain:\n",
    "                f[:, :n_vars] += self.aug_noise * torch.randn_like(f[:, :n_vars]) * f[:, n_vars:]\n",
    "            f = torch.cat((f, torch.zeros_like(f[:, :1])), dim=1)\n",
    "            if self.training and self.aug_mask > 0 and not self.pretrain:\n",
    "                mask = torch.rand(f.shape[0]) < self.aug_mask\n",
    "                f[mask, :] = 0.\n",
    "                f[mask, -1] = 1.\n",
    "            xs_ts[i] = f\n",
    "        n_timesteps = [len(ts) for ts in times]\n",
    "\n",
    "        # Pad the time series to the same length\n",
    "        pad_to = np.max(n_timesteps)\n",
    "        xs_ts = torch.stack([F.pad(t, (0, 0, 0, pad_to - t.shape[0])) for t in xs_ts]).to(self.device)\n",
    "        xs_times = torch.stack([F.pad(t, (0, pad_to - t.shape[0])) for t in times]).to(self.device)\n",
    "        xs_static = torch.stack(xs_static).to(self.device)\n",
    "\n",
    "        # Apply noise augmentation to the static features if needed\n",
    "        if self.training and self.aug_noise > 0 and not self.pretrain:\n",
    "            xs_static += self.aug_noise * torch.randn_like(xs_static)\n",
    "\n",
    "        return xs_static, xs_ts, xs_times, n_timesteps\n",
    "\n",
    "    def pretrain_prep_batch(self, x, batch_size):\n",
    "        \"\"\"Prepare a batch for pretraining.\"\"\"\n",
    "        xs_static, xs_ts, xs_times, n_timesteps = self.feats_to_input(x, batch_size)\n",
    "        n_steps = xs_ts.shape[1]\n",
    "        n_vars = (xs_ts.shape[2] - 1) // 2\n",
    "        y_ts = []\n",
    "        y_ts_n_obs = []\n",
    "        y_events = []\n",
    "        y_events_mask = []\n",
    "        xs_ts_clipped = xs_ts.clone()\n",
    "        for batch_i, n in enumerate(n_timesteps):\n",
    "            if n < 2:\n",
    "                mask_i = n\n",
    "            elif self.pretrain_masked_steps > 1:\n",
    "                if self.pretrain_masked_steps > n:\n",
    "                    mask_i = np.arange(n)\n",
    "                else:\n",
    "                    mask_i = self.rng.choice(np.arange(n), size=self.pretrain_masked_steps)\n",
    "            else:\n",
    "                mask_i = self.rng.choice(np.arange(0, n))\n",
    "            y_ts.append(xs_ts[batch_i, mask_i, :n_vars])\n",
    "            y_ts_n_obs.append(xs_ts[batch_i, mask_i, n_vars:2 * n_vars])\n",
    "\n",
    "            xs_ts_clipped[batch_i, mask_i, :] = 0.\n",
    "            xs_ts_clipped[batch_i, mask_i, -1] = 1.\n",
    "\n",
    "            if self.predict_events:\n",
    "                event_mask_i = self.rng.choice(np.arange(0, self.d_time_series_num))\n",
    "                y_events.append(xs_ts[batch_i, :, event_mask_i])\n",
    "                y_events_mask.append(xs_ts[batch_i, :, event_mask_i + n_vars].clip(0, 1))\n",
    "                xs_ts_clipped[batch_i, :, event_mask_i] = 0\n",
    "                xs_ts_clipped[batch_i, :, event_mask_i + n_vars] = -1\n",
    "\n",
    "        y_ts = torch.stack(y_ts)\n",
    "        y_ts_n_obs = torch.stack(y_ts_n_obs)\n",
    "        y_ts_masks = y_ts_n_obs.clip(0, 1)\n",
    "        if len(y_events) > 0:\n",
    "            y_events = torch.stack(y_events)\n",
    "            y_events_mask = torch.stack(y_events_mask)\n",
    "        if self.pretrain_dropout > 0:\n",
    "            keep = self.rng.random((batch_size, n_vars)) > self.pretrain_dropout\n",
    "            keep = torch.tensor(keep, device=xs_ts.device)\n",
    "            # Only drop out values that are unmasked in y\n",
    "            if y_ts_masks.ndim > 2:\n",
    "                keep = torch.logical_or(1 - y_ts_masks.sum(dim=1).clip(0, 1), keep)\n",
    "            else:\n",
    "                keep = torch.logical_or(1 - y_ts_masks, keep)\n",
    "            keep = torch.cat((keep.tile(1, 2), torch.ones((batch_size, 1), device=keep.device)), dim=1)\n",
    "            xs_ts_clipped *= torch.logical_or(keep.unsqueeze(1), xs_ts_clipped == -1)\n",
    "        return (xs_static, xs_ts_clipped, xs_times, n_timesteps), y_ts, y_ts_masks, y_events, y_events_mask\n",
    "\n",
    "    def forward(self, x, pretrain=False, representation=False):\n",
    "        \"\"\"\n",
    "        Forward run\n",
    "        :param x: input to the model\n",
    "        :return: prediction output (i.e., class probabilities vector)\n",
    "        \"\"\"\n",
    "        # Unpack the input data\n",
    "        xs_static, xs_feats, xs_times, n_timesteps = x\n",
    "\n",
    "        # Determine the number of variables in the time series data\n",
    "        n_vars = xs_feats.shape[2] // 2\n",
    "\n",
    "        # If event prediction is enabled, create a mask for the events\n",
    "        if self.predict_events:\n",
    "            event_mask_inds = xs_feats[:, :, n_vars:n_vars*2] == -1\n",
    "            event_mask_inds = torch.cat((event_mask_inds, torch.zeros(xs_feats.shape[:2] + (1,), device=xs_feats.device, dtype=torch.bool)), dim=2)\n",
    "            event_mask_inds = torch.cat((event_mask_inds, event_mask_inds[:, :1, :]), dim=1)\n",
    "\n",
    "        # Convert the number of observations to integers and clip to the range of the embedding\n",
    "        n_obs_inds = xs_feats[:, :, n_vars:n_vars*2].to(int).clip(0, self.n_obs_embedding.num_embeddings - 1)\n",
    "\n",
    "        # Replace the number of observations in the features with their embeddings\n",
    "        xs_feats[:, :, n_vars:n_vars*2] = self.n_obs_embedding(n_obs_inds).squeeze(-1)\n",
    "\n",
    "        # Prepare the input for the embedding layers\n",
    "        embedding_layer_input = torch.empty(xs_feats.shape[:-1] + (n_vars, 2), dtype=xs_feats.dtype, device=xs_feats.device)\n",
    "        embedding_layer_input[:, :, :, 0] = xs_feats[:, :, :n_vars]\n",
    "        embedding_layer_input[:, :, :, 1] = xs_feats[:, :, n_vars:n_vars*2]\n",
    "\n",
    "        # Initialize the output tensor for the embeddings\n",
    "        psi = torch.zeros((xs_feats.shape[0], xs_feats.shape[1]+1, n_vars+1, self.d_embedding), dtype=xs_feats.dtype, device=xs_feats.device)\n",
    "\n",
    "        # Apply each embedding layer to its corresponding input features\n",
    "        for i, el in enumerate(self.embedding_layers):\n",
    "            psi[:, :-1, i, :] = el(embedding_layer_input[:, :, i, :])\n",
    "\n",
    "        # Apply the tabular encoder to the static features\n",
    "        psi[:, :-1, -1, :] = self.tab_encoder(xs_static).unsqueeze(1)\n",
    "\n",
    "        # Add the special representation embedding to the last time step\n",
    "        psi[:, -1, :, :] = self.special_embeddings(self.REPRESENTATION_EMBEDDING_KEY.to(self.device)).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        # Create a mask for the special masked embedding\n",
    "        mask_inds = torch.cat((xs_feats[:, :, -1] == 1, torch.zeros((xs_feats.shape[0], 1), device=xs_feats.device, dtype=torch.bool)), dim=1)\n",
    "\n",
    "        # Apply the special masked embedding to the masked indices\n",
    "        psi[mask_inds, :, :] = self.special_embeddings(self.MASKED_EMBEDDING_KEY.to(self.device))\n",
    "\n",
    "        # If event prediction is enabled, apply the special masked embedding to the event mask indices\n",
    "        if self.predict_events:\n",
    "            psi[event_mask_inds, :] = self.special_embeddings(self.MASKED_EMBEDDING_KEY.to(self.device))\n",
    "\n",
    "        # Create the full time embeddings\n",
    "        time_embeddings = self.full_time_embedding(xs_times.unsqueeze(2))\n",
    "        time_embeddings = torch.cat((time_embeddings,\n",
    "            self.full_rep_embedding.weight.T.unsqueeze(0).expand(xs_feats.shape[0], -1, -1)),\n",
    "            dim=1)\n",
    "\n",
    "        # Apply each transformer layer to the embeddings\n",
    "        for layer_i, (event_transformer, time_transformer) in enumerate(zip(self.event_transformers, self.time_transformers)):\n",
    "            et_out_shape = (psi.shape[0], psi.shape[2], psi.shape[1], psi.shape[3])\n",
    "            embeddings = psi.transpose(1, 2).flatten(2) + self.full_event_embedding.weight.unsqueeze(0)\n",
    "            event_outs = event_transformer(embeddings).view(et_out_shape).transpose(1, 2)\n",
    "            tt_out_shape = event_outs.shape\n",
    "            embeddings = event_outs.flatten(2) + time_embeddings\n",
    "            psi = time_transformer(embeddings).view(tt_out_shape)\n",
    "\n",
    "        # Flatten the last two dimensions of the transformed embeddings\n",
    "        transformed = psi.flatten(2)\n",
    "\n",
    "        # Determine the method for fusing the embeddings\n",
    "        if self.fusion_method == 'rep_token':\n",
    "            z_ts = transformed[:, -1, :]\n",
    "        elif self.fusion_method == 'masked_embed':\n",
    "            if self.pretrain_masked_steps > 1:\n",
    "                masked_ind = F.pad(xs_feats[:, :, -1] > 0, (0, 1), value=False)\n",
    "                z_ts = []\n",
    "                for i in range(transformed.shape[0]):\n",
    "                    z_ts.append(F.pad(transformed[i, masked_ind[i], :], (0, 0, 0, self.pretrain_masked_steps - masked_ind[i].sum()), value=0.))\n",
    "                z_ts = torch.stack(z_ts)  # batch size x pretrain_masked_steps x d_embedding\n",
    "            else:\n",
    "                masked_ind = xs_feats[:, :, -1:]\n",
    "                z_ts = []\n",
    "                for i in range(transformed.shape[0]):\n",
    "                    z_ts.append(transformed[i, torch.nonzero(masked_ind[i].squeeze() == 1), :])\n",
    "                z_ts = torch.cat(z_ts, dim=0).squeeze()\n",
    "        elif self.fusion_method == 'averaging':\n",
    "            z_ts = torch.mean(transformed[:, :-1, :], dim=1)\n",
    "\n",
    "        # Set the final embeddings\n",
    "        z = z_ts\n",
    "\n",
    "        # If only the representation is needed, return it\n",
    "        if representation:\n",
    "            return z\n",
    "\n",
    "        # If pretraining is enabled, prepare the pretraining outputs\n",
    "        if pretrain:\n",
    "            rep_token_head = torch.tile(transformed[:, 0, :].unsqueeze(1), (1, self.masked_transform_timesteps, 1))\n",
    "            y_hat_presence = self.pretrain_presence_proj(z).squeeze() if self.pretrain_presence else None\n",
    "            y_hat_value = self.pretrain_value_proj(z).squeeze(1) if self.pretrain_value else None\n",
    "            z_events = []\n",
    "            y_hat_events, y_hat_events_presence = None, None\n",
    "            if self.predict_events:\n",
    "                for i in range(event_mask_inds.shape[0]):\n",
    "                    z_events.append(psi[i][event_mask_inds[i].nonzero(as_tuple=True)].flatten())\n",
    "                z_events = torch.stack(z_events)\n",
    "                y_hat_events = self.predict_events_proj(z_events).squeeze()\n",
    "                y_hat_events_presence = self.predict_events_presence_proj(z_events).squeeze() if self.pretrain_presence else None\n",
    "            return y_hat_value, y_hat_presence, y_hat_events, y_hat_events_presence\n",
    "\n",
    "        # If pretraining is not enabled, apply the head to the embeddings to get the final output\n",
    "        out = self.head(z).squeeze(1)\n",
    "\n",
    "        # If the representation is to be saved, return it along with the output\n",
    "        if self.save_representation:\n",
    "            return out, z\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure the optimizer for the model.\"\"\"\n",
    "        optimizers = [torch.optim.AdamW([p for l in self.modules() for p in l.parameters()],\n",
    "                                        lr=self.lr, weight_decay=self.weight_decay)]\n",
    "        return optimizers\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Perform a training step.\"\"\"\n",
    "        # Unpack the batch\n",
    "        x, y = batch\n",
    "        y = torch.tensor(y, dtype=torch.float64, device=self.device)\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        # If pretraining is enabled, prepare the pretraining outputs\n",
    "        if self.pretrain:\n",
    "            x_pretrain, y, mask, y_events, y_events_mask = self.pretrain_prep_batch(x, batch_size)\n",
    "            y_hat_value, y_hat_presence, y_hat_events, y_hat_events_presence = self.forward(x_pretrain, pretrain=True)\n",
    "\n",
    "            # Calculate the pretraining loss\n",
    "            loss = 0\n",
    "            if self.pretrain_value:\n",
    "                if self.pretrain_masked_steps > 1:\n",
    "                    for i in range(self.pretrain_masked_steps):\n",
    "                        loss += self.pretrain_loss(y_hat_value[:, i] * mask[:, i], y[:, i] * mask[:, i])\n",
    "                    loss /= self.pretrain_masked_steps\n",
    "                else:\n",
    "                    loss = self.pretrain_loss(y_hat_value * mask, y * mask)\n",
    "            if self.pretrain_presence:\n",
    "                if self.pretrain_masked_steps > 1:\n",
    "                    presence_loss = 0\n",
    "                    for i in range(self.pretrain_masked_steps):\n",
    "                        presence_loss += self.pretrain_presence_loss(y_hat_presence[:, i], mask[:, i]) * self.pretrain_presence_weight\n",
    "                    presence_loss /= self.pretrain_masked_steps\n",
    "                else:\n",
    "                    presence_loss = self.pretrain_presence_loss(y_hat_presence, mask) * self.pretrain_presence_weight\n",
    "                loss += presence_loss\n",
    "            if self.predict_events:\n",
    "                if self.pretrain_value:\n",
    "                    loss += self.pretrain_loss(y_hat_events * y_events_mask, y_events * y_events_mask)\n",
    "                if self.pretrain_presence:\n",
    "                    loss += self.pretrain_presence_loss(y_hat_events_presence, y_events_mask) * self.pretrain_presence_weight\n",
    "        else:\n",
    "            # If pretraining is not enabled, calculate the loss normally\n",
    "            y_hat = self.forward(self.feats_to_input(x, batch_size))\n",
    "            if self.pos_frac is not None:\n",
    "                weight = torch.where(y > 0, self.pos_weight, self.neg_weight)\n",
    "                loss = self.loss_function(y_hat, y, weight)\n",
    "            else:\n",
    "                loss = self.loss_function(y_hat, y)\n",
    "            self.train_auroc.update(y_hat, y.to(int))\n",
    "            self.train_ap.update(y_hat, y.to(int))\n",
    "\n",
    "        # Log the training loss\n",
    "        self.log('train_loss', loss, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Perform a validation step.\"\"\"\n",
    "        # Unpack the batch\n",
    "        x, y = batch\n",
    "        y = torch.tensor(y, dtype=torch.float64, device=self.device)\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        # If pretraining is enabled, prepare the pretraining outputs\n",
    "        if self.pretrain:\n",
    "            x_pretrain, y, mask, y_events, y_events_mask = self.pretrain_prep_batch(x, batch_size)\n",
    "            y_hat_value, y_hat_presence, y_hat_events, y_hat_events_presence = self.forward(x_pretrain, pretrain=True)\n",
    "\n",
    "            # Calculate the pretraining loss\n",
    "            loss = 0\n",
    "            if self.pretrain_value:\n",
    "                if self.pretrain_masked_steps > 1:\n",
    "                    for i in range(self.pretrain_masked_steps):\n",
    "                        loss += self.pretrain_loss(y_hat_value[:, i] * mask[:, i], y[:, i] * mask[:, i])\n",
    "                    loss /= self.pretrain_masked_steps\n",
    "                else:\n",
    "                    loss = self.pretrain_loss(y_hat_value * mask, y * mask)\n",
    "                self.log('val_next_loss', loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "            if self.pretrain_presence:\n",
    "                if self.pretrain_masked_steps > 1:\n",
    "                    presence_loss = 0\n",
    "                    for i in range(self.pretrain_masked_steps):\n",
    "                        presence_loss += self.pretrain_presence_loss(y_hat_presence[:, i], mask[:, i]) * self.pretrain_presence_weight\n",
    "                    presence_loss /= self.pretrain_masked_steps\n",
    "                else:\n",
    "                    presence_loss = self.pretrain_presence_loss(y_hat_presence, mask) * self.pretrain_presence_weight\n",
    "                self.log('val_presence_loss', presence_loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "                loss += presence_loss\n",
    "            if self.predict_events:\n",
    "                event_loss = self.pretrain_loss(y_hat_events * y_events_mask, y_events * y_events_mask)\n",
    "                self.log('val_event_loss', event_loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "                loss += event_loss\n",
    "            self.validation_step_outputs.append(loss)\n",
    "        else:\n",
    "            # If pretraining is not enabled, calculate the loss normally\n",
    "            y_hat = self.forward(self.feats_to_input(x, batch_size))\n",
    "            if self.pos_frac is not None:\n",
    "                weight = torch.where(y > 0, self.pos_weight, self.neg_weight)\n",
    "                loss = self.loss_function(y_hat, y, weight)\n",
    "            else:\n",
    "                loss = self.loss_function(y_hat, y)\n",
    "            self.validation_step_outputs.append(loss)\n",
    "            self.val_auroc.update(y_hat, y.to(int).to(self.device))\n",
    "            self.val_ap.update(y_hat, y.to(int).to(self.device))\n",
    "\n",
    "        # Log the validation metrics\n",
    "        if not self.pretrain:\n",
    "            self.log('val_ap', self.val_ap, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "            self.log('val_auroc', self.val_auroc, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "        self.log('val_loss', loss, on_epoch=True, sync_dist=True, prog_bar=True, rank_zero_only=True)\n",
    "\n",
    "    # This method is called at the end of each training epoch\n",
    "    def on_train_epoch_end(self):\n",
    "        # If not in pretraining mode, log the training metrics\n",
    "        if not self.pretrain:\n",
    "            self.log('train_auroc', self.train_auroc, sync_dist=True, rank_zero_only=True)\n",
    "            self.log('train_ap', self.train_ap, sync_dist=True, rank_zero_only=True)\n",
    "\n",
    "    # This method is called at the end of each validation epoch\n",
    "    def on_validation_epoch_end(self):\n",
    "        # If not in pretraining mode, print the validation metrics and clear the validation outputs\n",
    "        if not self.pretrain:\n",
    "            print(\"val_auroc\", self.val_auroc.compute(), \"val_ap\", self.val_ap.compute())\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    # This method is called for each test step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = torch.tensor(y, dtype=torch.float64, device=self.device)\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        # If save_representation is True, save the representations\n",
    "        if self.save_representation:\n",
    "            y_hat, z = self.forward(self.feats_to_input(x, batch_size))\n",
    "\n",
    "            print(\"saving representations...\")\n",
    "            with open(self.save_representation, 'ab') as f:\n",
    "                if y.ndim == 1:\n",
    "                    np.savetxt(f, np.concatenate([z.cpu(), y.unsqueeze(1).cpu()], axis=1))\n",
    "                else:\n",
    "                    np.savetxt(f, np.concatenate([z.cpu(), y.cpu()], axis=1))\n",
    "        else:\n",
    "            y_hat = self.forward(self.feats_to_input(x, batch_size))\n",
    "\n",
    "        # If pos_frac is not None, calculate the loss with weights\n",
    "        if self.pos_frac is not None:\n",
    "            weight = torch.where(y > 0, self.pos_weight, self.neg_weight)\n",
    "            loss = self.loss_function(y_hat, y, weight)\n",
    "        else:\n",
    "            loss = self.loss_function(y_hat, y)\n",
    "\n",
    "        # Log the test metrics\n",
    "        self.log('test_loss', loss, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "        self.test_auroc.update(y_hat, y.to(int).to(self.device))\n",
    "        self.log('test_auroc', self.test_auroc, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "        self.test_ap.update(y_hat, y.to(int).to(self.device))\n",
    "        self.log('test_ap', self.test_ap, on_epoch=True, sync_dist=True, rank_zero_only=True)\n",
    "\n",
    "        return loss, self.test_auroc, self.test_ap\n",
    "\n",
    "    # This method is called when a checkpoint is loaded\n",
    "    def on_load_checkpoint(self, checkpoint):\n",
    "        print('Loading from checkpoint')\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        model_state_dict = self.state_dict()\n",
    "        is_changed = False\n",
    "\n",
    "        # Update the state_dict with missing keys from the model_state_dict\n",
    "        for k in model_state_dict:\n",
    "            if k not in state_dict:\n",
    "                state_dict[k] = model_state_dict[k]\n",
    "                is_changed = True\n",
    "\n",
    "        # Check for mismatched shapes in the state_dict and model_state_dict\n",
    "        for k in state_dict:\n",
    "            if k in model_state_dict:\n",
    "                if k.startswith('head') and state_dict[k].shape != model_state_dict[k].shape:\n",
    "                    print(f\"Skip loading parameter: {k}, \"\n",
    "                          f\"required shape: {model_state_dict[k].shape}, \"\n",
    "                          f\"loaded shape: {state_dict[k].shape}\")\n",
    "                    state_dict[k] = model_state_dict[k]\n",
    "                    is_changed = True\n",
    "            else:\n",
    "                print(f\"Dropping parameter {k}\")\n",
    "                is_changed = True\n",
    "\n",
    "        # If the state_dict was changed, remove the optimizer states from the checkpoint\n",
    "        if is_changed:\n",
    "            checkpoint.pop(\"optimizer_states\", None)\n",
    "\n",
    "        # If freeze_encoder is True, freeze the model parameters\n",
    "        if self.freeze_encoder:\n",
    "            self.freeze()\n",
    "\n",
    "    # This method is used to freeze the model parameters\n",
    "    def freeze(self):\n",
    "        print('Freezing')\n",
    "        for n, w in self.named_parameters():\n",
    "            if \"head\" not in n:\n",
    "                w.requires_grad = False\n",
    "            else:\n",
    "                print(\"Skip freezing:\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb176e-c442-4f0e-b648-b2bd33a56a59",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now that the data-object is defined, as well as the model itself, the next step is to setup the logic for training the model as per the approach taken by the original authors in the project; this is done by implementing the DuETT. The below sections highlight the **hyper-parameters** used in the training of the model as well as the **computational parameters** defined.\n",
    "\n",
    "#### Hyper-Parameters\n",
    "1. **d_static_num**: This is the dimensionality of the static input features. It helps the model understand the size of the static input data.\n",
    "2. **d_time_series_num**: This is the dimensionality of the time series input features. It helps the model understand the size of the time series input data.\n",
    "3. **d_target**: This is the dimensionality of the target output. It helps the model understand the size of the output data.\n",
    "4. **lr (learning rate)**: This is the step size at each iteration while moving toward a minimum of a loss function. It determines how fast or slow the model will learn.\n",
    "5. **weight_decay**: This is a regularization term that discourages large weights in the model to prevent overfitting.\n",
    "6. **transformer_dropout**: This is the dropout rate for the transformer layers. It can help prevent overfitting by randomly setting a fraction of inputs to zero during training.\n",
    "7. **max_epochs**: This is the maximum number of passes over the entire dataset. It determines how long the model will be trained. This was tweaked during the training to ensure that we are able to run the code on the limited hardware we have.\n",
    "8. **gradient_clip_val**: This is the maximum allowed value for the gradients. It prevents the gradients from becoming too large and causing numerical instability.\n",
    "\n",
    "#### Computational Requirements\n",
    "1. **batch_size**: This is the number of samples that will be propagated through the network at once. It affects the speed and memory usage of model training.\n",
    "2. **num_workers**: This is the number of subprocesses to use for data loading. More workers can increase the speed of data loading.\n",
    "3. **seed**: This is the random seed for reproducibility. It ensures that the model's results are consistent across different runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0c587-5e3e-41bf-81b6-b828abef7bf0",
   "metadata": {},
   "source": [
    "#### Learning-Rate Adjustment\n",
    "This is an adjustment that is applied in the initial phase of the training (also known as the warm-up training phase). The task here is to gradually increase the learning rate over a provided number of steps. This is to prevent massive weight updates from the get-go of the training that can lead to divergence or poor convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "141bef4d-5cc3-4d00-b5f5-34152c4a9875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WarmUpCallback(pl.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    This class is a PyTorch Lightning callback that implements a linear warmup for optimizer's learning rate.\n",
    "    It increases the learning rate linearly for a certain number of steps (batches), and then decreases it\n",
    "    according to the inverse square root schedule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, steps=1000, base_lr=None, invsqrt=True, decay=None):\n",
    "        \"\"\"\n",
    "        Initializes the callback.\n",
    "\n",
    "        Args:\n",
    "            steps (int): Number of steps for the warmup phase.\n",
    "            base_lr (float, optional): Initial learning rate. If None, it will be inferred from the optimizer.\n",
    "            invsqrt (bool): If True, decrease the learning rate using the inverse square root schedule after the warmup phase.\n",
    "            decay (int, optional): Decay rate for the inverse square root schedule. If None, it will be equal to the number of warmup steps.\n",
    "        \"\"\"\n",
    "        print(f'warmup_steps {steps}, base_lr {base_lr}, invsqrt {invsqrt}, decay {decay}')\n",
    "        self.warmup_steps = steps\n",
    "        self.decay = steps if decay is None else decay\n",
    "        self.state = {'steps': 0, 'base_lr': float(base_lr) if base_lr is not None else base_lr}\n",
    "        self.invsqrt = invsqrt\n",
    "\n",
    "    def set_lr(self, optimizer, lr):\n",
    "        \"\"\"\n",
    "        Sets the learning rate for all parameter groups in the optimizer.\n",
    "\n",
    "        Args:\n",
    "            optimizer (Optimizer): The optimizer.\n",
    "            lr (float): The learning rate.\n",
    "        \"\"\"\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def on_train_batch_start(self, trainer, model, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        This method is called at the beginning of each training batch.\n",
    "        It adjusts the learning rate according to the schedule.\n",
    "\n",
    "        Args:\n",
    "            trainer (Trainer): The PyTorch Lightning trainer.\n",
    "            model (LightningModule): The model that is being trained.\n",
    "            batch: The current batch data.\n",
    "            batch_idx (int): The index of the current batch.\n",
    "        \"\"\"\n",
    "        optimizers = model.optimizers()\n",
    "\n",
    "        if self.state['steps'] < self.warmup_steps:\n",
    "            # During the warmup phase, increase the learning rate linearly.\n",
    "            if isinstance(optimizers, list):\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = [o.param_groups[0]['lr'] for o in optimizers]\n",
    "                for opt, base in zip(optimizers, self.state['base_lr']):\n",
    "                    self.set_lr(opt, self.state['steps'] / self.warmup_steps * base)\n",
    "            else:\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = optimizers.param_groups[0]['lr']\n",
    "                self.set_lr(optimizers, self.state['steps'] / self.warmup_steps * self.state['base_lr'])\n",
    "            self.state['steps'] += 1\n",
    "        elif self.invsqrt:\n",
    "            # After the warmup phase, decrease the learning rate using the inverse square root schedule.\n",
    "            if isinstance(optimizers, list):\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = [o.param_groups[0]['lr'] for o in optimizers]\n",
    "                for opt, base in zip(optimizers, self.state['base_lr']):\n",
    "                    self.set_lr(opt, base * (self.decay / (self.state['steps'] - self.warmup_steps + self.decay)) ** 0.5)\n",
    "            else:\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = optimizers.param_groups[0]['lr']\n",
    "                self.set_lr(optimizers, self.state['base_lr'] * (self.decay / (self.state['steps'] - self.warmup_steps + self.decay)) ** 0.5)\n",
    "            self.state['steps'] += 1\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"\n",
    "        Loads the state of the callback from a dictionary.\n",
    "\n",
    "        Args:\n",
    "            state_dict (dict): A dictionary containing the state of the callback.\n",
    "        \"\"\"\n",
    "        self.state.update(state_dict)\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing the state of the callback.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the state of the callback.\n",
    "        \"\"\"\n",
    "        return self.state.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ef225-cb5c-4d30-92e0-24f5dfd8c023",
   "metadata": {},
   "source": [
    "#### Methods to Assist With Training Process\n",
    "The following methods are called throughout the training process; the key methods are:\n",
    "    1. **Pre-Training**: This is where the model is initialized for pre-training\n",
    "    2. **Fine-Tuning**: This method is invoked after the initial round of trainings as part of the DuETT task that this project is experimenting with.\n",
    "    3. **Averaging-Models**: Once we have different versions of the fine-tuned model, we average them to get the *best* model (according to this paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d7e2002-d633-4a3e-b4ae-76f3124d808d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretrain_model(d_static_num, d_time_series_num, d_target, **kwargs):\n",
    "    \"\"\"\n",
    "    This function initializes a model for pretraining.\n",
    "\n",
    "    Args:\n",
    "        d_static_num (int): The dimensionality of the static input features.\n",
    "        d_time_series_num (int): The dimensionality of the time-series input features.\n",
    "        d_target (int): The dimensionality of the target output.\n",
    "        **kwargs: Additional keyword arguments for the Model constructor.\n",
    "\n",
    "    Returns:\n",
    "        Model: The initialized model.\n",
    "    \"\"\"\n",
    "    return Model(d_static_num, d_time_series_num, d_target, **kwargs)\n",
    "\n",
    "\n",
    "def fine_tune_model(ckpt_path, **kwargs):\n",
    "    \"\"\"\n",
    "    This function loads a pretrained model from a checkpoint and prepares it for fine-tuning.\n",
    "\n",
    "    Args:\n",
    "        ckpt_path (str): The path to the checkpoint file.\n",
    "        **kwargs: Additional keyword arguments for the Model constructor.\n",
    "\n",
    "    Returns:\n",
    "        Model: The model loaded from the checkpoint.\n",
    "    \"\"\"\n",
    "    return Model.load_from_checkpoint(\n",
    "        ckpt_path,\n",
    "        pretrain=False,\n",
    "        aug_noise=0.,\n",
    "        aug_mask=0.5,\n",
    "        transformer_dropout=0.5,\n",
    "        lr=1.e-4,\n",
    "        weight_decay=1.e-5,\n",
    "        fusion_method='rep_token',\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def average_models(models):\n",
    "    \"\"\"\n",
    "    This function averages the weights of a list of models and loads the resulting weights into the first model.\n",
    "\n",
    "    Args:\n",
    "        models (list): A list of models whose weights are to be averaged.\n",
    "\n",
    "    Returns:\n",
    "        Model: The first model in the list, but with the weights replaced by their average.\n",
    "    \"\"\"\n",
    "    models = list(models)\n",
    "    n = len(models)\n",
    "    sds = [m.state_dict() for m in models]\n",
    "    averaged = {}\n",
    "\n",
    "    for k in sds[0]:\n",
    "        averaged[k] = sum(sd[k] for sd in sds) / n\n",
    "\n",
    "    models[0].load_state_dict(averaged)\n",
    "    return models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9eaf2d-d551-4e79-834a-9ae65cf0cf11",
   "metadata": {},
   "source": [
    "#### Pre-Train the Model\n",
    "As part of the pre-training, we:\n",
    "1. Initialize the data-module .\n",
    "2. Define the model pre-training parameter setup.\n",
    "3. Define the checkpoint-tracking so that the model with the best results is recorded during pre-training.\n",
    "4. Define the learning rate for the process.\n",
    "\n",
    "The code setup in the above code cells is referrred to here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41b0a1ac-ce37-4907-a2a7-049465a87bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating cache...\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup_steps 2000, base_lr None, invsqrt True, decay None\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/ec2-user/SageMaker/checkpoints exists and is not empty.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/optim/adamw.py:50: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type                   | Params\n",
      "-------------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding              | 192   \n",
      "1  | embedding_layers             | ModuleList             | 67.7 K\n",
      "2  | n_obs_embedding              | Embedding              | 16    \n",
      "3  | event_transformers           | ModuleList             | 1.8 M \n",
      "4  | full_event_embedding         | Embedding              | 29.3 K\n",
      "5  | time_transformers            | ModuleList             | 2.0 M \n",
      "6  | full_time_embedding          | Sequential             | 26.8 K\n",
      "7  | full_rep_embedding           | Embedding              | 888   \n",
      "8  | head                         | Sequential             | 57.1 K\n",
      "9  | pretrain_value_proj          | Sequential             | 32.0 K\n",
      "10 | pretrain_presence_proj       | Sequential             | 32.0 K\n",
      "11 | predict_events_proj          | Sequential             | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential             | 25.4 K\n",
      "13 | tab_encoder                  | Sequential             | 4.5 K \n",
      "14 | train_auroc                  | BinaryAUROC            | 0     \n",
      "15 | val_auroc                    | BinaryAUROC            | 0     \n",
      "16 | train_ap                     | BinaryAveragePrecision | 0     \n",
      "17 | val_ap                       | BinaryAveragePrecision | 0     \n",
      "18 | test_auroc                   | BinaryAUROC            | 0     \n",
      "19 | test_ap                      | BinaryAveragePrecision | 0     \n",
      "-------------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.279    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64342f62ab3440e19e7ff001e81c8de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6a9d03c410488ab61c23161fb1f738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e91132abbd40c0a87996ff6a57e1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783938c36eab4a3faaf6d1d669c4fcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b04743ef91e42768338f932a6a5ea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd168b1e2f48402b992ba605e23e81d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f199f67f78cb4490aad2f71b30600552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebf5ecad1f449e09dfc88ac8cae6621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e49f4ab7ead4f589613bbaf5e5ca072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.3977024257183075\n",
      "       test_auroc           0.7883566617965698\n",
      "        test_loss           0.6280285530276216\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6280285530276216,\n",
       "  'test_auroc': 0.7883566617965698,\n",
       "  'test_ap': 0.3977024257183075}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 2020\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "# Initialize the data module\n",
    "dm = PhysioNetDataModule(batch_size=64, num_workers=2, use_temp_cache=True)\n",
    "dm.setup()\n",
    "\n",
    "# Initialize the pretraining model\n",
    "pretrain_model = pretrain_model(\n",
    "    d_static_num=dm.d_static_num(),\n",
    "    d_time_series_num=dm.d_time_series_num(),\n",
    "    d_target=dm.d_target(),\n",
    "    pos_frac=dm.pos_frac(),\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Initialize the checkpoint callback for saving the best model during pretraining\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    dirpath='checkpoints'\n",
    ")\n",
    "\n",
    "# Initialize the warmup callback for learning rate scheduling\n",
    "warmup = WarmUpCallback(steps=2000)\n",
    "\n",
    "# Initialize the trainer and start pretraining\n",
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    num_sanity_val_steps=2,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[warmup, checkpoint],\n",
    "    accelerator='cpu'\n",
    ")\n",
    "trainer.fit(pretrain_model, dm)\n",
    "\n",
    "# Get the path of the pretrained model\n",
    "pretrained_path = checkpoint.best_model_path\n",
    "\n",
    "trainer.test(final_model, dataloaders=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb880d6a-b837-4fa5-9d55-08c7c2531141",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fine-Tune Model\n",
    "Once the pre-training is complete, we fine-tune the model across different seeds and record the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1da1409a-e195-4770-85a4-fa66dd745308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2020\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint\n",
      "warmup_steps 1000, base_lr None, invsqrt True, decay None\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/ec2-user/SageMaker/checkpoints exists and is not empty.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/optim/adamw.py:50: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type                   | Params\n",
      "-------------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding              | 192   \n",
      "1  | embedding_layers             | ModuleList             | 67.7 K\n",
      "2  | n_obs_embedding              | Embedding              | 16    \n",
      "3  | event_transformers           | ModuleList             | 1.8 M \n",
      "4  | full_event_embedding         | Embedding              | 29.3 K\n",
      "5  | time_transformers            | ModuleList             | 2.0 M \n",
      "6  | full_time_embedding          | Sequential             | 26.8 K\n",
      "7  | full_rep_embedding           | Embedding              | 888   \n",
      "8  | head                         | Sequential             | 57.1 K\n",
      "9  | pretrain_value_proj          | Sequential             | 32.0 K\n",
      "10 | pretrain_presence_proj       | Sequential             | 32.0 K\n",
      "11 | predict_events_proj          | Sequential             | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential             | 25.4 K\n",
      "13 | tab_encoder                  | Sequential             | 4.5 K \n",
      "14 | train_auroc                  | BinaryAUROC            | 0     \n",
      "15 | val_auroc                    | BinaryAUROC            | 0     \n",
      "16 | train_ap                     | BinaryAveragePrecision | 0     \n",
      "17 | val_ap                       | BinaryAveragePrecision | 0     \n",
      "18 | test_auroc                   | BinaryAUROC            | 0     \n",
      "19 | test_ap                      | BinaryAveragePrecision | 0     \n",
      "-------------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.279    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.3772) val_ap tensor(0.1448)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b566bc4350e34c6aab444e39976c0641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.6551) val_ap tensor(0.2331)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7085) val_ap tensor(0.2670)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7099) val_ap tensor(0.2787)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7358) val_ap tensor(0.3073)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7217) val_ap tensor(0.3362)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.6740) val_ap tensor(0.3242)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7602) val_ap tensor(0.3823)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7983) val_ap tensor(0.3913)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7957) val_ap tensor(0.3830)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7820) val_ap tensor(0.3789)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7805) val_ap tensor(0.3703)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8018) val_ap tensor(0.3881)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7955) val_ap tensor(0.3757)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7952) val_ap tensor(0.3762)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8024) val_ap tensor(0.4193)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8115) val_ap tensor(0.4280)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8088) val_ap tensor(0.4103)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8087) val_ap tensor(0.4292)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8096) val_ap tensor(0.4190)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8087) val_ap tensor(0.4479)\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Validating cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c306cbe1084714890fbbfe5974560c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2021\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.44990038871765137\n",
      "       test_auroc           0.7970470786094666\n",
      "        test_loss           0.5783784175941128\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading from checkpoint\n",
      "warmup_steps 1000, base_lr None, invsqrt True, decay None\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/ec2-user/SageMaker/checkpoints exists and is not empty.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/optim/adamw.py:50: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type                   | Params\n",
      "-------------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding              | 192   \n",
      "1  | embedding_layers             | ModuleList             | 67.7 K\n",
      "2  | n_obs_embedding              | Embedding              | 16    \n",
      "3  | event_transformers           | ModuleList             | 1.8 M \n",
      "4  | full_event_embedding         | Embedding              | 29.3 K\n",
      "5  | time_transformers            | ModuleList             | 2.0 M \n",
      "6  | full_time_embedding          | Sequential             | 26.8 K\n",
      "7  | full_rep_embedding           | Embedding              | 888   \n",
      "8  | head                         | Sequential             | 57.1 K\n",
      "9  | pretrain_value_proj          | Sequential             | 32.0 K\n",
      "10 | pretrain_presence_proj       | Sequential             | 32.0 K\n",
      "11 | predict_events_proj          | Sequential             | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential             | 25.4 K\n",
      "13 | tab_encoder                  | Sequential             | 4.5 K \n",
      "14 | train_auroc                  | BinaryAUROC            | 0     \n",
      "15 | val_auroc                    | BinaryAUROC            | 0     \n",
      "16 | train_ap                     | BinaryAveragePrecision | 0     \n",
      "17 | val_ap                       | BinaryAveragePrecision | 0     \n",
      "18 | test_auroc                   | BinaryAUROC            | 0     \n",
      "19 | test_ap                      | BinaryAveragePrecision | 0     \n",
      "-------------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.279    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e491a25f00c44b29af296f684d66930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.3772) val_ap tensor(0.1448)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e3247ce24947d28e352039e0b428ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.6587) val_ap tensor(0.2289)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7115) val_ap tensor(0.2694)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7130) val_ap tensor(0.2772)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7485) val_ap tensor(0.3050)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7586) val_ap tensor(0.3325)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7468) val_ap tensor(0.3398)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7643) val_ap tensor(0.3178)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7536) val_ap tensor(0.3646)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7586) val_ap tensor(0.3450)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7696) val_ap tensor(0.3738)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7797) val_ap tensor(0.3508)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7782) val_ap tensor(0.3561)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7645) val_ap tensor(0.3453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7341) val_ap tensor(0.3319)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7725) val_ap tensor(0.3515)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7793) val_ap tensor(0.3780)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7879) val_ap tensor(0.3928)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7911) val_ap tensor(0.3906)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7934) val_ap tensor(0.3880)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7873) val_ap tensor(0.3954)\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Validating cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7acd761f6b14230ae1b8f7efc268a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.34840890765190125\n",
      "       test_auroc           0.7875723838806152\n",
      "        test_loss           0.5696057305793529\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup_steps 1000, base_lr None, invsqrt True, decay None\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/ec2-user/SageMaker/checkpoints exists and is not empty.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/optim/adamw.py:50: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type                   | Params\n",
      "-------------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding              | 192   \n",
      "1  | embedding_layers             | ModuleList             | 67.7 K\n",
      "2  | n_obs_embedding              | Embedding              | 16    \n",
      "3  | event_transformers           | ModuleList             | 1.8 M \n",
      "4  | full_event_embedding         | Embedding              | 29.3 K\n",
      "5  | time_transformers            | ModuleList             | 2.0 M \n",
      "6  | full_time_embedding          | Sequential             | 26.8 K\n",
      "7  | full_rep_embedding           | Embedding              | 888   \n",
      "8  | head                         | Sequential             | 57.1 K\n",
      "9  | pretrain_value_proj          | Sequential             | 32.0 K\n",
      "10 | pretrain_presence_proj       | Sequential             | 32.0 K\n",
      "11 | predict_events_proj          | Sequential             | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential             | 25.4 K\n",
      "13 | tab_encoder                  | Sequential             | 4.5 K \n",
      "14 | train_auroc                  | BinaryAUROC            | 0     \n",
      "15 | val_auroc                    | BinaryAUROC            | 0     \n",
      "16 | train_ap                     | BinaryAveragePrecision | 0     \n",
      "17 | val_ap                       | BinaryAveragePrecision | 0     \n",
      "18 | test_auroc                   | BinaryAUROC            | 0     \n",
      "19 | test_ap                      | BinaryAveragePrecision | 0     \n",
      "-------------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.279    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.3772) val_ap tensor(0.1448)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4b36aeb1024b79a9ba63342dfe28fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.5939) val_ap tensor(0.2050)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7109) val_ap tensor(0.2678)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7308) val_ap tensor(0.2864)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7691) val_ap tensor(0.3444)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7480) val_ap tensor(0.3261)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7683) val_ap tensor(0.3787)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7675) val_ap tensor(0.3694)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7572) val_ap tensor(0.3397)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7691) val_ap tensor(0.3456)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7851) val_ap tensor(0.3734)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7914) val_ap tensor(0.3872)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7896) val_ap tensor(0.3765)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7991) val_ap tensor(0.4085)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.7879) val_ap tensor(0.3343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8103) val_ap tensor(0.4187)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8059) val_ap tensor(0.4111)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8065) val_ap tensor(0.4067)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8133) val_ap tensor(0.4270)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8096) val_ap tensor(0.4224)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.8073) val_ap tensor(0.4349)\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Validating cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7f2b597a944bc1a3794356503cc6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.43770408630371094\n",
      "       test_auroc           0.8056058883666992\n",
      "        test_loss           0.5694958295419178\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Validating cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcac47484a74c2ea53bf1c92b23478b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.43770408630371094\n",
      "       test_auroc           0.8056058883666992\n",
      "        test_loss           0.5694958295419178\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5694958295419178,\n",
       "  'test_auroc': 0.8056058883666992,\n",
       "  'test_ap': 0.43770408630371094}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model for different seeds\n",
    "final_model = None\n",
    "for seed in range(2020, 2023):\n",
    "    pl.seed_everything(seed)\n",
    "    fine_tuned_model = fine_tune_model(\n",
    "        pretrained_path,\n",
    "        d_static_num=dm.d_static_num(),\n",
    "        d_time_series_num=dm.d_time_series_num(),\n",
    "        d_target=dm.d_target(),\n",
    "        pos_frac=dm.pos_frac(),\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Initialize the checkpoint callback for saving the best models during fine-tuning\n",
    "    checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "        save_top_k=5,\n",
    "        save_last=False,\n",
    "        mode='max',\n",
    "        monitor='val_ap',\n",
    "        dirpath='checkpoints'\n",
    "    )\n",
    "\n",
    "    # Initialize the warmup callback for learning rate scheduling\n",
    "    warmup = WarmUpCallback(steps=1000)\n",
    "\n",
    "    # Initialize the trainer and start fine-tuning\n",
    "    trainer = pl.Trainer(\n",
    "        logger=False,\n",
    "        max_epochs=20,\n",
    "        gradient_clip_val=1.0,\n",
    "        callbacks=[warmup, checkpoint],\n",
    "        accelerator='cpu'\n",
    "    )\n",
    "    trainer.fit(fine_tuned_model, dm)\n",
    "\n",
    "    # Average the weights of the best models and test the final model\n",
    "    final_model = average_models([\n",
    "        fine_tune_model(\n",
    "            path,\n",
    "            d_static_num=dm.d_static_num(),\n",
    "            d_time_series_num=dm.d_time_series_num(),\n",
    "            d_target=dm.d_target(),\n",
    "            pos_frac=dm.pos_frac()\n",
    "        ) for path in checkpoint.best_k_models.keys()\n",
    "    ])\n",
    "    trainer.test(final_model, dataloaders=dm)\n",
    "\n",
    "# Test the final model\n",
    "trainer.test(final_model, dataloaders=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7c234-3d8e-4479-9f86-4bf4d641a817",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Below, we will discuss the results of this experiment. The following are the 3 key metrics discussed here:\n",
    "1. **Loss Score**: This is the value of the loss function on the test set. The loss function measures the difference between the model's predictions and the actual values. In general, a lower loss value is better as it indicates that the model's predictions are close to the actual values.\n",
    "2. **AUROC Score**: This is the Area Under the Receiver Operating Characteristic curve (AUROC) on the test set. The AUROC is a measure of how well a model can distinguish between different classes. The value ranges from 0 to 1, where a value of 0.5 indicates a model that is no better than random guessing, and a value of 1 indicates a perfect model.\n",
    "3. **Average Precision**: This is the Average Precision (AP) on the test set. The AP summarizes the precision-recall curve, which shows the trade-off between precision and recall for different threshold. A higher AP indicates better precision and recall balance. The value ranges from 0 to 1, where a value of 1 indicates a perfect model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e8cc3-adda-46ff-a85b-19e99606a182",
   "metadata": {},
   "source": [
    "#### Evaluate Base Model\n",
    "\n",
    "At this point, we have the base iteration of our model, which will be fine-tuned as per the DuETT implementation. These are the metrics returned. \n",
    "\n",
    "| Loss Score         | AUROC Score        | Average Precision  |\n",
    "| ------------------ | ------------------ | ------------------ |\n",
    "| 0.6280285530276216 | 0.7883566617965698 | 0.3977024257183075 |\n",
    "\n",
    "The key metrics surfaced here are:\n",
    "1. **test_loss**: Our model's test loss is `0.6280285530276216`, which is fairly high.\n",
    "2. **test_auroc**: Our model's test AUROC is `0.7883566617965698`, which is reasonably good.\n",
    "3. **test_ap**: Our model's test AP is `0.3977024257183075`, which is not very high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e15ebd-1cb6-4de1-a659-c5838d7e35cd",
   "metadata": {},
   "source": [
    "#### Evaluate Final Model\n",
    "\n",
    "At this point, we have the final iteration of the model, post fine-tuning. As seen in the code above, the fine-tuning is performed across multiple `seed` values, and it returns the following scores:\n",
    "\n",
    "| Seed | Loss Score         | AUROC Score        | Average Precision   |\n",
    "| ---- | ------------------ | ------------------ | ------------------- |\n",
    "| 2020 | 0.5696057305793529 | 0.8056058883666992 | 0.43770408630371094 |\n",
    "| 2021 | 0.5696057305793529 | 0.7875723838806152 | 0.34840890765190125 |\n",
    "| 2022 | 0.5783784175941128 | 0.7970470786094666 | 0.44990038871765137 |\n",
    "\n",
    "The key metrics surfaced here are:\n",
    "1. **Loss Score**: Our model's lowest test loss is `0.5696057305793529`.\n",
    "2. **AUROC Score**: Our model's test AUROC is `0.8056058883666992`.\n",
    "3. **Average Precision**: Our model's test AP is `0.44990038871765137`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06a136-6925-415d-9fe5-df23a6ce112d",
   "metadata": {},
   "source": [
    "#### Comparisons\n",
    "If we compare the 3 key metrics:\n",
    "\n",
    "1. **Loss Score**: We see a significant improvement in the fine-tuned model over the pretrained model. This score also falls closely in line with the scores seen in the original paper from the author (see *Table 2* on [page 15](https://arxiv.org/pdf/2304.13017)), actually being an improvement despite fewer training epochs.\n",
    "2. **AUROC Score**: We see a significant improvement in the fine-tuned model over the pretrained model. However, due to machine limitations, the score still comes out lower than what was in the paper by ~0.6% (see *Table 1* on [page 12](https://arxiv.org/pdf/2304.13017)). It is interesting to note that the AUROC went up from 0.59 to 0.81 during the training; therefore, it is safe to assume that if we fine-tuned the model for 50 epochs instead of 20, we would have reached much closer to the paper's results.\n",
    "3. **Average Precision**: This is not a metric studied in the paper; however, we see a significant improvement in the fine-tuned model over the pretrained model.\n",
    "\n",
    "##### Comparing to Hypothesis\n",
    "Comparing these results on `Physionet2012` with the findings on the MIMIC-IV dataset recorded in the paper indicate that we were able to reproduce similar results, and demonstrate the effectiveness of self-supervised learning (SSL) to build a strong model without having to rely on a massive dataset (e.g MIMIC-IV). Desipte the sparsity of the `Physionet2012` dataset (with time-series fields being sporadically defined), the training results match the findings using the regular dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26659487-596e-472b-acbd-eed683a020b6",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "### Implications\n",
    "Given that we were largely able to obtain similar results to what was achieved in the paper (improved result scores for some metrics, and slightly diminished results in other cases), this paper has a high reproducibility.\n",
    "\n",
    "### What Was Easy\n",
    "This paper had many strenghts that made it easy to replicate:\n",
    "1. The biggest benefit of replicating this author's project was the simplicity of accessing the dataset; the main data-set that all the hypotheses can simply be imported as a Python package and integrated into the code, all of which is already set up. \n",
    "2. The code is also compact in nature, as well as well-structured (although with minimal to no comments) and organized, which makes it a lot easier to trace and understand as part of replicating it. \n",
    "\n",
    "### Challenges\n",
    "Despite the benefits, there were still some issues faced when replicating this paper.\n",
    "1. The main concern was setting up the environment. The Python version used by the authors is not specified; therefore, I had to tweak the dependencies using trial-and-error when running the code for the first time on my local computer. This problem amplified when attempting to upload my code and running it on an online instance, because the default Python version in Google Collab and AWS SageMaker was Python 3.10.3, and changing that was near-impossible. This meant that I:\n",
    "    1. Had to remove all dependency versions and install the latest ones to break the conflict issues.\n",
    "    2. Make modifications to the code because some dependencies ƒrom the [requirements.txt](https://github.com/layer6ai-labs/DuETT/blob/master/requirements.txt) of the package were severely outdated, and the API specifications had changed. \n",
    "2. Another problem was the computing requirements. Despite being a smaller dataset, my local computer would fail halfway into the training process due to a lack of memory. Google Collab was not helpful as its processor was even weaker than my local computers. I had to then set up an AWS SageMaker notebook on a powerful `ml.r7i.2xlarge` instance that was able to complete the entire training.\n",
    "\n",
    "### Feedback to Authors\n",
    "Despite the challenges above, the paper is well-written and implemented, making it easy to reproduce. My only feedback would be directed at using the latest version of dependencies, especially when uploading the code to a public repository for allowing anyone to reproduce it; given that the [requirements.txt](https://github.com/layer6ai-labs/DuETT/blob/master/requirements.txt) was only uploaded 9 months ago (from the time of writing this), an effort could have been made to rely on the newer dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6d35a-3657-4e72-ae56-7b6fe5630e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
